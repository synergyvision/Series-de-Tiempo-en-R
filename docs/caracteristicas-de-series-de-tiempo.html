<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
<<<<<<< HEAD
  <title>Series de Tiempo en R</title>
  <meta name="description" content="Series de Tiempo en R">
  <meta name="generator" content="bookdown 0.5.4 and GitBook 2.6.7">
=======
  <title>Capítulo 2 Características de series de tiempo | Series de Tiempo en R</title>
  <meta name="description" content="Capítulo 2 Características de series de tiempo | Series de Tiempo en R">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">
>>>>>>> d29c4667e48a2762d89d8c516304a5bee625c8e4

  <meta property="og:title" content="Capítulo 2 Características de series de tiempo | Series de Tiempo en R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://synergy.vision/Series-de-Tiempo-en-R/" />
  <meta property="og:image" content="http://synergy.vision/Series-de-Tiempo-en-R/images/cover.png" />
  
  <meta name="github-repo" content="synergyvision/Series-de-Tiempo-en-R/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 2 Características de series de tiempo | Series de Tiempo en R" />
  
  
  <meta name="twitter:image" content="http://synergy.vision/Series-de-Tiempo-en-R/images/cover.png" />

<meta name="author" content="Synergy Vision">


<<<<<<< HEAD
<meta name="date" content="2018-08-31">
=======
<meta name="date" content="2020-01-31">
>>>>>>> d29c4667e48a2762d89d8c516304a5bee625c8e4

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduccion.html">
<link rel="next" href="modelos-de-series-de-tiempo.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="images/logovision-black.png" width="160"></img></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#por-que-leer-este-libro"><i class="fa fa-check"></i>¿Por qué leer este libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#estructura-del-libro"><i class="fa fa-check"></i>Estructura del libro</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#informacion-sobre-los-programas-y-convenciones"><i class="fa fa-check"></i>Información sobre los programas y convenciones</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#practicas-interactivas-con-r"><i class="fa fa-check"></i>Prácticas interactivas con R</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="acerca-del-autor.html"><a href="acerca-del-autor.html"><i class="fa fa-check"></i>Acerca del Autor</a></li>
<li class="chapter" data-level="1" data-path="introduccion.html"><a href="introduccion.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="introduccion.html"><a href="introduccion.html#conceptos-financieros-basicos"><i class="fa fa-check"></i><b>1.1</b> Conceptos financieros básicos</a></li>
<li class="chapter" data-level="1.2" data-path="introduccion.html"><a href="introduccion.html#conceptos-basicos"><i class="fa fa-check"></i><b>1.2</b> Conceptos básicos</a></li>
<li class="chapter" data-level="1.3" data-path="introduccion.html"><a href="introduccion.html#ejemplos"><i class="fa fa-check"></i><b>1.3</b> Ejemplos</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduccion.html"><a href="introduccion.html#clasificacion-de-las-series-de-tiempo"><i class="fa fa-check"></i><b>1.3.1</b> Clasificación de las series de tiempo</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduccion.html"><a href="introduccion.html#componentes-de-una-serie-de-tiempo"><i class="fa fa-check"></i><b>1.4</b> Componentes de una serie de tiempo</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduccion.html"><a href="introduccion.html#el-modelo-aditivo-de-componentes-de-series-de-tiempo"><i class="fa fa-check"></i><b>1.4.1</b> El Modelo Aditivo de Componentes de Series de Tiempo</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduccion.html"><a href="introduccion.html#el-modelo-multiplicativo-de-componentes-de-series-de-tiempo"><i class="fa fa-check"></i><b>1.4.2</b> El Modelo Multiplicativo de Componentes de Series de Tiempo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="caracteristicas-de-series-de-tiempo.html"><a href="caracteristicas-de-series-de-tiempo.html"><i class="fa fa-check"></i><b>2</b> Características de series de tiempo</a><ul>
<li class="chapter" data-level="2.1" data-path="caracteristicas-de-series-de-tiempo.html"><a href="caracteristicas-de-series-de-tiempo.html#medidas-de-dependencia-para-series-de-tiempo"><i class="fa fa-check"></i><b>2.1</b> Medidas de dependencia para series de tiempo</a></li>
<li class="chapter" data-level="2.2" data-path="caracteristicas-de-series-de-tiempo.html"><a href="caracteristicas-de-series-de-tiempo.html#estimacion-de-la-tendencia"><i class="fa fa-check"></i><b>2.2</b> Estimación de la Tendencia</a><ul>
<li class="chapter" data-level="2.2.1" data-path="caracteristicas-de-series-de-tiempo.html"><a href="caracteristicas-de-series-de-tiempo.html#estimacion-de-la-tendencia-en-ausencia-de-estacionalidad"><i class="fa fa-check"></i><b>2.2.1</b> Estimación de la tendencia en ausencia de estacionalidad</a></li>
<li class="chapter" data-level="2.2.2" data-path="caracteristicas-de-series-de-tiempo.html"><a href="caracteristicas-de-series-de-tiempo.html#estimacion-de-la-tendencia-y-la-estacionalidad"><i class="fa fa-check"></i><b>2.2.2</b> Estimación de la tendencia y la estacionalidad</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="caracteristicas-de-series-de-tiempo.html"><a href="caracteristicas-de-series-de-tiempo.html#estimacion-de-la-tendencia-por-regresion-clasica"><i class="fa fa-check"></i><b>2.3</b> Estimación de la tendencia por regresión clásica</a><ul>
<li class="chapter" data-level="2.3.1" data-path="caracteristicas-de-series-de-tiempo.html"><a href="caracteristicas-de-series-de-tiempo.html#regresion-clasica"><i class="fa fa-check"></i><b>2.3.1</b> Regresión Clásica</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html"><i class="fa fa-check"></i><b>3</b> Modelos de series de tiempo</a><ul>
<li class="chapter" data-level="3.1" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#modelos-estocasticos"><i class="fa fa-check"></i><b>3.1</b> Modelos Estocásticos</a><ul>
<li class="chapter" data-level="3.1.1" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#procesos-estocasticos"><i class="fa fa-check"></i><b>3.1.1</b> Procesos Estocásticos</a></li>
<li class="chapter" data-level="3.1.2" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#momentos-varianza-covarianza-y-correlacion"><i class="fa fa-check"></i><b>3.1.2</b> Momentos, Varianza, Covarianza y Correlación</a></li>
<li class="chapter" data-level="3.1.3" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#variacion-de-un-proceso"><i class="fa fa-check"></i><b>3.1.3</b> Variación de un proceso</a></li>
<li class="chapter" data-level="3.1.4" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#martingalas"><i class="fa fa-check"></i><b>3.1.4</b> Martingalas</a></li>
<li class="chapter" data-level="3.1.5" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#propiedad-de-markov"><i class="fa fa-check"></i><b>3.1.5</b> Propiedad de Markov</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#modelos-lineales"><i class="fa fa-check"></i><b>3.2</b> Modelos lineales</a><ul>
<li class="chapter" data-level="3.2.1" data-path="modelos-de-series-de-tiempo.html"><a href="modelos-de-series-de-tiempo.html#proceso-de-ruido-blanco"><i class="fa fa-check"></i><b>3.2.1</b> Proceso de Ruido Blanco</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modelos-ar.html"><a href="modelos-ar.html"><i class="fa fa-check"></i><b>4</b> Modelos AR</a><ul>
<li class="chapter" data-level="4.1" data-path="modelos-ar.html"><a href="modelos-ar.html#modelo-ar1"><i class="fa fa-check"></i><b>4.1</b> Modelo AR(1)</a></li>
<li class="chapter" data-level="4.2" data-path="modelos-ar.html"><a href="modelos-ar.html#modelo-ar2"><i class="fa fa-check"></i><b>4.2</b> Modelo AR(2)</a></li>
<li class="chapter" data-level="4.3" data-path="modelos-ar.html"><a href="modelos-ar.html#procesos-arp"><i class="fa fa-check"></i><b>4.3</b> Procesos AR(p)</a></li>
<li class="chapter" data-level="4.4" data-path="modelos-ar.html"><a href="modelos-ar.html#funcion-de-autocorrelacion-parcial"><i class="fa fa-check"></i><b>4.4</b> Función de Autocorrelación Parcial</a></li>
<li class="chapter" data-level="4.5" data-path="modelos-ar.html"><a href="modelos-ar.html#criterios-de-informacion"><i class="fa fa-check"></i><b>4.5</b> Criterios de Información</a></li>
<li class="chapter" data-level="4.6" data-path="modelos-ar.html"><a href="modelos-ar.html#estimacion-de-parametros."><i class="fa fa-check"></i><b>4.6</b> Estimación de Parámetros.</a></li>
<li class="chapter" data-level="4.7" data-path="modelos-ar.html"><a href="modelos-ar.html#predicciones-con-modelos-ar"><i class="fa fa-check"></i><b>4.7</b> Predicciones con modelos AR</a><ul>
<li class="chapter" data-level="4.7.1" data-path="modelos-ar.html"><a href="modelos-ar.html#prediccion-de-un-paso"><i class="fa fa-check"></i><b>4.7.1</b> Predicción de un paso</a></li>
<li class="chapter" data-level="4.7.2" data-path="modelos-ar.html"><a href="modelos-ar.html#prediccion-de-dos-pasos"><i class="fa fa-check"></i><b>4.7.2</b> Predicción de dos pasos</a></li>
<li class="chapter" data-level="4.7.3" data-path="modelos-ar.html"><a href="modelos-ar.html#prediccion-de-multiples-pasos"><i class="fa fa-check"></i><b>4.7.3</b> Predicción de múltiples pasos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modelos-ma.html"><a href="modelos-ma.html"><i class="fa fa-check"></i><b>5</b> Modelos MA</a><ul>
<li class="chapter" data-level="5.1" data-path="modelos-ma.html"><a href="modelos-ma.html#propiedades-de-los-modelos-ma"><i class="fa fa-check"></i><b>5.1</b> Propiedades de los modelos MA</a><ul>
<li class="chapter" data-level="5.1.1" data-path="modelos-ma.html"><a href="modelos-ma.html#estacionaridad"><i class="fa fa-check"></i><b>5.1.1</b> Estacionaridad</a></li>
<li class="chapter" data-level="5.1.2" data-path="modelos-ma.html"><a href="modelos-ma.html#funcion-de-autocorrelacion-acf"><i class="fa fa-check"></i><b>5.1.2</b> Función de autocorrelación (ACF)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modelos-ma.html"><a href="modelos-ma.html#identificacion-del-orden-de-un-ma"><i class="fa fa-check"></i><b>5.2</b> Identificación del orden de un MA</a></li>
<li class="chapter" data-level="5.3" data-path="modelos-ma.html"><a href="modelos-ma.html#estimacion"><i class="fa fa-check"></i><b>5.3</b> Estimación</a></li>
<li class="chapter" data-level="5.4" data-path="modelos-ma.html"><a href="modelos-ma.html#predicciones-usando-modelos-ma"><i class="fa fa-check"></i><b>5.4</b> Predicciones usando modelos MA</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelos-arma.html"><a href="modelos-arma.html"><i class="fa fa-check"></i><b>6</b> Modelos ARMA</a><ul>
<li class="chapter" data-level="6.1" data-path="modelos-arma.html"><a href="modelos-arma.html#propiedades-de-los-modelos-armapq"><i class="fa fa-check"></i><b>6.1</b> Propiedades de los modelos ARMA(p,q)</a></li>
<<<<<<< HEAD
<li class="chapter" data-level="6.2" data-path="modelos-arma.html"><a href="modelos-arma.html#ecuaciones-en-diferencias"><i class="fa fa-check"></i><b>6.2</b> Ecuaciones en Diferencias</a></li>
<li class="chapter" data-level="6.3" data-path="modelos-arma.html"><a href="modelos-arma.html#la-densidad-espectral"><i class="fa fa-check"></i><b>6.3</b> La Densidad Espectral</a></li>
<li class="chapter" data-level="6.4" data-path="modelos-arma.html"><a href="modelos-arma.html#periodograma-y-transformada-discreta-de-fourier"><i class="fa fa-check"></i><b>6.4</b> Periodograma y Transformada Discreta de Fourier</a></li>
<li class="chapter" data-level="6.5" data-path="modelos-arma.html"><a href="modelos-arma.html#estimacion-espectral-no-parametrica"><i class="fa fa-check"></i><b>6.5</b> Estimación Espectral No-paramétrica</a></li>
<li class="chapter" data-level="6.6" data-path="modelos-arma.html"><a href="modelos-arma.html#procesos-de-incremento-ortogonal-sobre--pipi"><i class="fa fa-check"></i><b>6.6</b> Procesos de Incremento Ortogonal sobre <span class="math inline">\([-\pi,\pi]\)</span></a></li>
<li class="chapter" data-level="6.7" data-path="modelos-arma.html"><a href="modelos-arma.html#integracion-con-respecto-a-un-proceso-de-incremento-ortogonal"><i class="fa fa-check"></i><b>6.7</b> Integración con Respecto a un Proceso de Incremento Ortogonal</a><ul>
<li class="chapter" data-level="6.7.1" data-path="modelos-arma.html"><a href="modelos-arma.html#propiedades-de-la-integral-estocastica"><i class="fa fa-check"></i><b>6.7.1</b> Propiedades de la Integral Estocástica</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="modelos-arma.html"><a href="modelos-arma.html#la-representacion-espectral"><i class="fa fa-check"></i><b>6.8</b> La Representación Espectral</a></li>
=======
<li class="chapter" data-level="6.2" data-path="modelos-arma.html"><a href="modelos-arma.html#ecuaciones-en-diferencias"><i class="fa fa-check"></i><b>6.2</b> Ecuaciones en Diferencias</a><ul>
<li class="chapter" data-level="6.2.1" data-path="modelos-arma.html"><a href="modelos-arma.html#funcion-de-autocorrelacion-acf-para-modelos-arma"><i class="fa fa-check"></i><b>6.2.1</b> Función de Autocorrelación (ACF) para modelos ARMA</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="modelos-arma.html"><a href="modelos-arma.html#pronosticos"><i class="fa fa-check"></i><b>6.3</b> Pronósticos</a><ul>
<li class="chapter" data-level="6.3.1" data-path="modelos-arma.html"><a href="modelos-arma.html#pronosticos-para-procesos-arma"><i class="fa fa-check"></i><b>6.3.1</b> Pronósticos para procesos ARMA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimacion-de-parametros.html"><a href="estimacion-de-parametros.html"><i class="fa fa-check"></i><b>7</b> Estimación de parámetros</a><ul>
<li class="chapter" data-level="7.1" data-path="estimacion-de-parametros.html"><a href="estimacion-de-parametros.html#estimacion-1"><i class="fa fa-check"></i><b>7.1</b> Estimación</a></li>
<li class="chapter" data-level="7.2" data-path="estimacion-de-parametros.html"><a href="estimacion-de-parametros.html#sect-EMV"><i class="fa fa-check"></i><b>7.2</b> Estimación por Máxima Verosimilitud y Mínimos Cuadrados</a></li>
<li class="chapter" data-level="7.3" data-path="estimacion-de-parametros.html"><a href="estimacion-de-parametros.html#estimacion-de-minimos-cuadrados-para-modelos-armapq"><i class="fa fa-check"></i><b>7.3</b> Estimación de mínimos cuadrados para modelos ARMA(p,q)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelos-arima.html"><a href="modelos-arima.html"><i class="fa fa-check"></i><b>8</b> Modelos ARIMA</a><ul>
<li class="chapter" data-level="8.1" data-path="modelos-arima.html"><a href="modelos-arima.html#construccion-de-modelos-arima"><i class="fa fa-check"></i><b>8.1</b> Construcción de modelos ARIMA</a></li>
<li class="chapter" data-level="8.2" data-path="modelos-arima.html"><a href="modelos-arima.html#modelos-sarima"><i class="fa fa-check"></i><b>8.2</b> Modelos SARIMA</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html"><i class="fa fa-check"></i><b>9</b> Modelos ARCH y GARCH</a><ul>
<li class="chapter" data-level="9.1" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html#estructura-de-los-modelos"><i class="fa fa-check"></i><b>9.1</b> Estructura de los Modelos</a></li>
<li class="chapter" data-level="9.2" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html#modelos-arch"><i class="fa fa-check"></i><b>9.2</b> Modelos ARCH</a><ul>
<li class="chapter" data-level="9.2.1" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html#estimacion-de-un-modelo-archp"><i class="fa fa-check"></i><b>9.2.1</b> Estimación de un Modelo ARCH(p)</a></li>
<li class="chapter" data-level="9.2.2" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html#prediccion-con-modelos-arch"><i class="fa fa-check"></i><b>9.2.2</b> Predicción con modelos ARCH</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html#modelos-garch"><i class="fa fa-check"></i><b>9.3</b> Modelos GARCH</a><ul>
<li class="chapter" data-level="9.3.1" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html#estimacion-de-un-modelo-garch"><i class="fa fa-check"></i><b>9.3.1</b> Estimación de un Modelo GARCH</a></li>
<li class="chapter" data-level="9.3.2" data-path="modelos-arch-y-garch.html"><a href="modelos-arch-y-garch.html#prediccion-con-modelos-garch"><i class="fa fa-check"></i><b>9.3.2</b> Predicción con modelos GARCH</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><i class="fa fa-check"></i><b>10</b> Modelos lineales estacionales y modelos no-estacionarios</a><ul>
<li class="chapter" data-level="10.1" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#modelos-estacionales"><i class="fa fa-check"></i><b>10.1</b> Modelos Estacionales</a></li>
<li class="chapter" data-level="10.2" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#modelos-de-memoria-larga"><i class="fa fa-check"></i><b>10.2</b> Modelos de memoria larga</a><ul>
<li class="chapter" data-level="10.2.1" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#diferenciacion-fraccionada"><i class="fa fa-check"></i><b>10.2.1</b> Diferenciación fraccionada</a></li>
<li class="chapter" data-level="10.2.2" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#ajuste-de-datos-simulados"><i class="fa fa-check"></i><b>10.2.2</b> Ajuste de datos simulados</a></li>
<li class="chapter" data-level="10.2.3" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#evaluacion-de-las-pruebas-de-dependencia-a-largo-plazo"><i class="fa fa-check"></i><b>10.2.3</b> Evaluación de las pruebas de dependencia a largo plazo</a></li>
<li class="chapter" data-level="10.2.4" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#simulacion"><i class="fa fa-check"></i><b>10.2.4</b> Simulación</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#modelos-no-estacionarios"><i class="fa fa-check"></i><b>10.3</b> Modelos no estacionarios</a><ul>
<li class="chapter" data-level="10.3.1" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#no-estacionarios-en-varianza"><i class="fa fa-check"></i><b>10.3.1</b> No estacionarios en Varianza</a></li>
<li class="chapter" data-level="10.3.2" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#no-estacionarios-en-media"><i class="fa fa-check"></i><b>10.3.2</b> No estacionarios en Media</a></li>
<li class="chapter" data-level="10.3.3" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#test-de-raiz-unitaria"><i class="fa fa-check"></i><b>10.3.3</b> Test de raíz unitaria</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#modelos-de-regresion"><i class="fa fa-check"></i><b>10.4</b> Modelos de regresión</a></li>
<li class="chapter" data-level="10.5" data-path="modelos-lineales-estacionales-y-modelos-no-estacionarios.html"><a href="modelos-lineales-estacionales-y-modelos-no-estacionarios.html#estimacion-consistente-de-la-matriz-de-covarianza"><i class="fa fa-check"></i><b>10.5</b> Estimación consistente de la matriz de covarianza</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analisis-espectral.html"><a href="analisis-espectral.html"><i class="fa fa-check"></i><b>11</b> Análisis Espectral</a><ul>
<li class="chapter" data-level="11.1" data-path="analisis-espectral.html"><a href="analisis-espectral.html#comportamiento-ciclico-y-periodicidad"><i class="fa fa-check"></i><b>11.1</b> Comportamiento Cíclico y Periodicidad</a></li>
<li class="chapter" data-level="11.2" data-path="analisis-espectral.html"><a href="analisis-espectral.html#la-densidad-espectral"><i class="fa fa-check"></i><b>11.2</b> La Densidad Espectral</a></li>
<li class="chapter" data-level="11.3" data-path="analisis-espectral.html"><a href="analisis-espectral.html#periodograma-y-transformada-discreta-de-fourier"><i class="fa fa-check"></i><b>11.3</b> Periodograma y Transformada Discreta de Fourier</a></li>
<li class="chapter" data-level="11.4" data-path="analisis-espectral.html"><a href="analisis-espectral.html#estimacion-espectral-no-parametrica"><i class="fa fa-check"></i><b>11.4</b> Estimación Espectral No-paramétrica</a></li>
<li class="chapter" data-level="11.5" data-path="analisis-espectral.html"><a href="analisis-espectral.html#procesos-de-incremento-ortogonal-sobre--pipi"><i class="fa fa-check"></i><b>11.5</b> Procesos de Incremento Ortogonal sobre <span class="math inline">\([-\pi,\pi]\)</span></a></li>
<li class="chapter" data-level="11.6" data-path="analisis-espectral.html"><a href="analisis-espectral.html#integracion-con-respecto-a-un-proceso-de-incremento-ortogonal"><i class="fa fa-check"></i><b>11.6</b> Integración con Respecto a un Proceso de Incremento Ortogonal</a><ul>
<li class="chapter" data-level="11.6.1" data-path="analisis-espectral.html"><a href="analisis-espectral.html#propiedades-de-la-integral-estocastica"><i class="fa fa-check"></i><b>11.6.1</b> Propiedades de la Integral Estocástica</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="analisis-espectral.html"><a href="analisis-espectral.html#la-representacion-espectral"><i class="fa fa-check"></i><b>11.7</b> La Representación Espectral</a></li>
>>>>>>> d29c4667e48a2762d89d8c516304a5bee625c8e4
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Series de Tiempo en R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="caracteristicas-de-series-de-tiempo" class="section level1">
<h1><span class="header-section-number">Capítulo 2</span> Características de series de tiempo</h1>
<p>El objetivo primario en el análisis de Series de Tiempo es desarrollar modelos matemáticos que provean una descripción apropiada para los datos muestrales, como los vistos en los ejemplos del capítulo anterior. Así, lo primero que hacemos es utilizar la definición <a href="introduccion.html#def:defi-serie-tiempo">1.7</a>, para tener un soporte estadístico. En este capítulo daremos algunas definiciones que serán de uso general en todo el resto del libro, también se describiran algunos métodos para el análisis exploratorio de las series de tiempo</p>
<div id="medidas-de-dependencia-para-series-de-tiempo" class="section level2">
<h2><span class="header-section-number">2.1</span> Medidas de dependencia para series de tiempo</h2>

<div class="definition">
<p><span id="def:defi-proceso-estocastico" class="definition"><strong>Definición 2.1  </strong></span>Un <strong>proceso estocástico</strong> es una familia de variables aleatorias indexadas <span class="math inline">\(x(\omega,t)\)</span> ó <span class="math inline">\(x_t(\omega)\)</span> donde <span class="math inline">\(t\)</span> pertenece a un conjunto de índices <span class="math inline">\(T\)</span> y <span class="math inline">\(\omega\)</span> pertenece a un espacio muestral <span class="math inline">\(\Omega\)</span>. Si <span class="math inline">\(t=t^*\)</span> fijo, <span class="math inline">\(x(\omega,t^*)\)</span> es una variable aleatoria. Si <span class="math inline">\(\omega=\omega^*\)</span> fijo, <span class="math inline">\(x(\omega^*,t)\)</span> es una función de <span class="math inline">\(t\)</span>, y se llama una <em>realización</em> del proceso. Una <strong>serie de tiempo</strong> es la realización de un proceso estocástico.</p>
</div>

<hr />
<p>Una descripción completa de una serie de tiempo, observada como una colección de <span class="math inline">\(n\)</span> variables aleatorias en puntos de tiempo enteros arbitrarios <span class="math inline">\(t_1,t_2,\ldots,t_n\)</span>, para cada entero positivo <span class="math inline">\(n\)</span>, es proporcionada por la función de distribución conjunta, evaluada como la probabilidad de que los valores de la serie sean conjuntamente menor que <span class="math inline">\(n\)</span> constantes <span class="math inline">\(c_1,c_2,\ldots,c_n\)</span>, esto es</p>
<span class="math display" id="eq:eq-distribucion-conjunta">\[\begin{equation}
F(c_1,c_2,\ldots,c_n)=P(x_{t_1}\leq c_1,x_{t_2}\leq c_2,\ldots,x_{t_n}\leq c_n).
\tag{2.1}
\end{equation}\]</span>
<p>Desafortunadamente, la función de distribución multidimensional usualmente no se puede escribir fácilmente a menos que las variables aleatorias tengan distribución normal conjunta, en cuyo caso, la ecuación <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-distribucion-conjunta">(2.1)</a> llega a ser la distribución normal multivariada usual.</p>
Un caso particular en la cual la función de distribución multidimensional es fácil de escribir, será en el caso de variables aleatorias normal estándar independientes e idénticamente distribuidas, para lo cual la función de distribución se puede expresar como el producto de las distribuciones marginales, es decir,
<span class="math display" id="eq:eq-distribucion-producto-marginal">\[\begin{equation}
F(c_1,c_2,\ldots,c_n)=\prod_{t_1}^{n}\Phi(c_t)
\tag{2.2}
\end{equation}\]</span>
donde
<span class="math display" id="eq:eq-distribucion-normal">\[\begin{equation}
\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}\mathbb{E}xp\left\{-\frac{z^2}{2}\right\}dz\tag{2.3}
\end{equation}\]</span>
<p>es la función de distribución normal estándar acumulada.</p>
<p>Aunque la función de distribución multidimensional describa los datos completamente, esto es un instrumento poco manejable para mostrar y analizar datos de series de tiempo. La función de distribución <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-distribucion-conjunta">(2.1)</a> debe ser evaluada como una función de <span class="math inline">\(n\)</span> argumentos, entonces cualquier graficación de las correspondientes funciones de densidad multivariante es prácticamente imposible. La función de distribución unidimensional <span class="math display">\[F_t(x)=P\{x_t\leq x\}\]</span> o la correspondiente función de densidad unidimensional <span class="math display">\[f_t(x)=\frac{\partial F_t(x)}{\partial x},\]</span> cuando existen, a menudo son más útiles para determinar si una coordenada en particular de la serie de tiempo tiene una función de densidad conocida, como la distribución normal (gaussiana), por ejemplo.</p>

<div class="definition">
<p><span id="def:defi-funcion-media" class="definition"><strong>Definición 2.2  </strong></span>La <strong>función de media</strong> es definida como</p>
<span class="math display" id="eq:eq-funcion-media">\[\begin{equation}
\mu_{xt}=\mathbb{E}(x_t)=\int_{-\infty}^{\infty}xf_t(x)dx,
\tag{2.4}
\end{equation}\]</span>
<p>en caso de que exista, donde <span class="math inline">\(\mathbb{E}\)</span> denota el operador usual de esperanza. Cuando no haya confusión sobre a que serie de tiempo nos referimos, escribiremos <span class="math inline">\(\mu_{xt}\)</span> como <span class="math inline">\(\mu_t\)</span>.</p>
</div>

<hr />
<p>Lo importante de comprender sobre <span class="math inline">\(\mu_t\)</span> consiste en que es una media teórica para la serie de tiempo en un punto particular, donde la media se asume o calcula sobre todos los posibles eventos que podrían haber producido <span class="math inline">\(x_t\)</span>.</p>

<div class="definition">
<span id="def:defi-funcion-autocovarianza" class="definition"><strong>Definición 2.3  </strong></span>La <strong>función de autocovarianza</strong> es definida como producto del segundo momento
<span class="math display" id="eq:eq-funcion-autocovarianza">\[\begin{equation}
\gamma_x(s,t)=\mathbb{E}[(x_s-\mu_s)(x_t-\mu_t)],
\tag{2.5}
\end{equation}\]</span>
<p>para todo <span class="math inline">\(t\)</span> y <span class="math inline">\(s\)</span>. cuando no haya confusión en la existencia sobre a que serie nos referimos, escribiremos <span class="math inline">\(\gamma_x(s,t)=\gamma(s,t)\)</span>.</p>
</div>

<hr />
Note que <span class="math inline">\(\gamma_x(s,t)=\gamma_x(t,s)\)</span> para todo los puntos <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span>. La función de autocovarianza mide la dependencia lineal entre dos puntos de la misma serie en diferentes tiempos. La autocovarianza <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-funcion-autocovarianza">(2.5)</a> es el promedio de los productos cruzados relacionado con la densidad conjunta <span class="math inline">\(F(x_s,x_t)\)</span>. Es claro que, para <span class="math inline">\(s=t\)</span>, la autocovarianza se reduce a la varianza (en el caso finito), dado que
<span class="math display" id="eq:eq-funcion-autocovarianza-varianza">\[\begin{equation}
\gamma_x(t,t)=\mathbb{E}[(x_t-\mu_t)^2]
\tag{2.6}
\end{equation}\]</span>
<p>Otro función de medida de tendencia importante es la <em>función de autocorrelación</em>.</p>

<div class="definition">
<span id="def:defi-acf" class="definition"><strong>Definición 2.4  </strong></span>La <strong>función de autocorrelación (ACF)</strong> (ACF, siglas en ingles: Autocorrelation Function) se define como
<span class="math display" id="eq:eq-funcion-autocorrelacion">\[\begin{equation}
\rho(s,t)=\frac{\gamma(s,t)}{\sqrt{\gamma(s,s)\gamma(t,t)}}
\tag{2.7}
\end{equation}\]</span>
</div>

<hr />
<p>La <span class="math inline">\(ACF\)</span> mide la predictibilidad lineal de una serie de tiempo en tiempo <span class="math inline">\(t\)</span>, digamos <span class="math inline">\(x_t\)</span> usando solo el valor <span class="math inline">\(x_s\)</span>. Es fácil de demostrar que <span class="math inline">\(-1\leq\rho(s,t)\leq1\)</span> usando la desigualdad de Cauchy-Schwarz<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>Si podemos predecir <span class="math inline">\(x_t\)</span> exactamente de <span class="math inline">\(x_s\)</span> a través de la relación lineal <span class="math inline">\(x_t=\beta_0+\beta_1x_s\)</span> entonces la correlación será 1 cuando <span class="math inline">\(\beta_1&gt;0\)</span> y <span class="math inline">\(-1\)</span> cuando <span class="math inline">\(\beta_1&lt;0\)</span>.</p>

<div class="definition">
<span id="def:defi-covarianza-cruzada" class="definition"><strong>Definición 2.5  </strong></span>La <strong>función de covarianza cruzada</strong> entre dos series <span class="math inline">\(x_t\)</span> y <span class="math inline">\(y_t\)</span> se define como
<span class="math display" id="eq:eq-funcion-covarianza-cruzada">\[\begin{equation}
\gamma_{xy}(s,t)=\mathbb{E}[(x_s-\mu_{xs})(y_t-\mu_{yt})]
\tag{2.8}
\end{equation}\]</span>
</div>

<hr />

<div class="definition">
<span id="def:defi-ccf" class="definition"><strong>Definición 2.6  </strong></span>La <strong>función de correlación cruzada (CCF)</strong> (CCF, siglas en ingles: Cross Correlation Function) es definida como
<span class="math display" id="eq:eq-funcion-correlacion-cruzada">\[\begin{equation}
\rho_{xy}(s,t)=\frac{\gamma_{xy}(s,t)}{\sqrt{\gamma_x(s,s)\gamma_y(t,t)}}
\tag{2.9}
\end{equation}\]</span>
</div>

<hr />
<p>Las definiciones anteriores de funciones de media y varianza son completamente generales. Aunque nosotros no hayamos hecho ninguna suposición especial sobre el comportamiento de las series de tiempo, muchos de los ejemplos precedentes han insinuado que puede existir una especie de regularidad en el comportamiento de las mismas. Introducimos la noción de regularidad que usa el concepto de <em>estacionaridad</em>, que ya hemos introducido empíricamente en el apartado 1.2.1 “Clasificación de las series de tiempo”</p>
<p>Formalmente tenemos las siguientes definiciones de estacionaridad</p>

<div class="definition">
<span id="def:defi-estricta-estacionaridad" class="definition"><strong>Definición 2.7  </strong></span>Una serie de tiempo <strong>estrictamente estacionaria</strong> es una serie para la cual el comportamiento probabilístico de cada sucesión de valores <span class="math display">\[\{x_{t_1},x_{t_2},\ldots,x_{t_k}\}\]</span> es idéntico a la serie trasladada en el tiempo <span class="math display">\[\{x_{t_1+h},x_{t_2+h},\ldots,x_{t_k+h}\}\]</span> Esto es,
<span class="math display" id="eq:eq-estricta-estacionaridad">\[\begin{equation}
P[X_{t_1}\leq c_1,\ldots,x_{t_k}\leq c_k] = P[X_{t_1+h}\leq c_1,\ldots,x_{t_k+h}\leq c_k]
\tag{2.10}
\end{equation}\]</span>
<p>para todo <span class="math inline">\(k=1,2,\ldots\)</span>, todo puntos de tiempos <span class="math inline">\(t_1,t_2,\ldots,t_k\)</span> y números <span class="math inline">\(c_1,c_2,\ldots,c_k\)</span> y todo salto <span class="math inline">\(h=\pm0,\pm1,\pm2,\ldots\)</span>.</p>
</div>

<hr />
<p>Esta definición de estacionaridad es muy fuerte para la mayoría de las aplicaciones prácticas. Por ello necesitamos una versión menos fuerte que imponga menos condiciones sobre las distribuciones de probabilidad, ya que si observamos bien la ecuación <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estricta-estacionaridad">(2.10)</a>, lo que nos dice la misma es que todas las posibles distribuciones de probabilidad deben ser iguales, lo que como ya indicamos en la práctica es muy difícil de comprobar aún para conjuntos de datos sencillos. La siguiente versión de estacionaridad solo impone condiciones sobre los dos primeros momentos de la serie</p>

<div class="definition">
<p><span id="def:defi-debilmente-estacionaria" class="definition"><strong>Definición 2.8  </strong></span>Una serie de tiempo <strong>débilmente estacionaria</strong> <span class="math inline">\(x_t\)</span>, es un proceso de varianza finita tal que</p>
<ol style="list-style-type: decimal">
<li><p>la función de media <span class="math inline">\(\mu_t\)</span> es constante y no depende del tiempo <span class="math inline">\(t\)</span>,</p></li>
<li><p>la función de covarianza <span class="math inline">\(\gamma(t,s)\)</span> depende solo de las diferencias de <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span>, <span class="math inline">\(|t-s|\)</span>.</p></li>
</ol>
<p>Por consiguiente, usaremos el término <strong>estacionaridad</strong> para referirnos a estacionaridad débil; si un proceso es estacionario en el sentido estricto usaremos el término <em>estrictamente estacionario</em>.</p>
</div>

<hr />

<div class="remark">
 <span class="remark"><em>Nota. </em></span>  1) Si una serie de tiempo es estrictamente estacionaria, entonces todos las funciones de distribución multivariadas para subconjuntos de variables deben coincidir con sus contrapartes en el conjunto trasladado, para todos los valores del parámetro <span class="math inline">\(h\)</span>. Por ejemplo para <span class="math inline">\(k=1\)</span> La ecuación <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estricta-estacionaridad">(2.10)</a> implica que
<span class="math display" id="eq:e1p20">\[\begin{equation}
        P\{x_s\leq c\}=P\{x_t\leq c\}
\tag{2.11}
\end{equation}\]</span>
<p>para cada puntos <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span>. Esta declaración implica, por ejemplo, que si la probabilidad de un valor de una serie de tiempo muestreada cada hora es negativa a la 1:00a.m, la probabilidad a la 10:00a.m. es la misma. Además, si la función de media, <span class="math inline">\(\mu_t\)</span> de la serie <span class="math inline">\(x_t\)</span> existe, <a href="caracteristicas-de-series-de-tiempo.html#eq:e1p20">(2.11)</a> implica que <span class="math inline">\(\mu_s=\mu_t\)</span> para todo <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span>, y por consiguiente <span class="math inline">\(\mu_t\)</span> debe ser constante.</p>
<ol start="2" style="list-style-type: decimal">
<li>Cuando <span class="math inline">\(k=2\)</span>, podemos escribir la ecuación <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estricta-estacionaridad">(2.10)</a> como
<span class="math display" id="eq:e1p21">\[\begin{equation}
  P\{x_s\leq c_1,x_t\leq c_2\}=P\{x_{s+h}\leq c_1,x_{t+h}\leq c_2\}
\tag{2.12}
\end{equation}\]</span>
para cada par de puntos <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span> y salto <span class="math inline">\(h\)</span>. Entonces, si la función de varianza del proceso existe, <a href="caracteristicas-de-series-de-tiempo.html#eq:e1p21">(2.12)</a> implica que la función de autocovarianza de la serie <span class="math inline">\(x_t\)</span> satisface <span class="math inline">\(\gamma(s,t)=\gamma(s+h,t+h)\)</span> para todos <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span> y salto <span class="math inline">\(h\)</span>.</li>
</ol>
<p>Podemos interpretar este resultado diciendo que la función de autocovarianza del proceso depende sólo de las diferencias de tiempo entre <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span>, y no del tiempo actual.</p>
</div>

<hr />
<p>Es claro de la definición <a href="caracteristicas-de-series-de-tiempo.html#def:defi-estricta-estacionaridad">2.7</a> de serie estrictamente estacionaria, que una serie de tiempo estrictamente estacionaria con varianza finita, también es una serie estacionaria. El recíproco no es cierto a menos que impongamos condicionaes adicionales. Un importante caso donde estacionaridad implica estricta estacionaridad es el caso de series de tiempo gaussianas.</p>
Ya que la función de media <span class="math inline">\(\mathbb{E}(x_t)=\mu_t\)</span> de una serie de tiempo estacionaria es independiente del tiempo <span class="math inline">\(t\)</span>, escribimos
<span class="math display" id="eq:e1p22">\[\begin{equation}
\mu_t=\mu
\tag{2.13}
\end{equation}\]</span>
Debido a que la función de covarianza de una serie de tiempo estacionaria, <span class="math inline">\(\gamma(s,t)\)</span> en tiempos <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span> depende sólo de la diferencia <span class="math inline">\(|s-t|\)</span>, podemos simplificar la notación. Sea <span class="math inline">\(s=t+h\)</span>, donde <span class="math inline">\(h\)</span> representa el tiempo de traslación o salto, entonces
<span class="math display" id="eq:eq-funcion-covarianza-estacionaria">\[\begin{eqnarray}
\gamma(s,t)&amp;=&amp;\mathbb{E}[(x_{t+h}-\mu)(x_t-\mu)]\\ \nonumber
    &amp;=&amp;\mathbb{E}[(x_h-\mu)(x_0-\mu)]\\
    &amp;=&amp;\gamma(h,0) \nonumber
    \tag{2.14}
\end{eqnarray}\]</span>
<p>no depende del argumento de tiempo <span class="math inline">\(t\)</span>; asumiendo que <span class="math inline">\(\text{Var}(x_t)=\gamma(0,0)&lt;\infty\)</span>. De ahora en adelante, por conveniencia, prescindiremos del segundo argumento de <span class="math inline">\(\gamma(h,0)\)</span>, es decir, la función de covarianza se denotará <span class="math inline">\(\gamma(h)\)</span>.</p>

<div class="definition">
<span id="def:defi-autocovarianza-serie-estacionaria" class="definition"><strong>Definición 2.9  </strong></span>La <strong>función de autocovarianza de una serie de tiempo estacionaria</strong> se escribirá como
<span class="math display" id="eq:eq-funcion-autocovarianza-estacionaria">\[\begin{equation}
\gamma(h)=\mathbb{E}[(x_{t+h}-\mu)(x_t-\mu)]
\tag{2.15}
\end{equation}\]</span>
</div>

<hr />

<div class="definition">
<span id="def:defi-acf-estacionaria" class="definition"><strong>Definición 2.10  </strong></span>La <strong>función de autocorrelación (ACF) de una serie de tiempo estacionaria</strong> será escrita, usando <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-funcion-autocorrelacion">(2.7)</a> como
<span class="math display" id="eq:eq-funcion-autocorrelacion-estacionaria">\[\begin{equation}
\rho(h)=\frac{\gamma(t+h,t)}{\sqrt{\gamma(t+h,t+h)\gamma(t,t)}}=\frac{\gamma(h)}{\gamma(0)}
\tag{2.16}
\end{equation}\]</span>
</div>

<hr />
<p>La desigualdad de Cauchy-Schwartz muestra nuevamente que <span class="math inline">\(-1\leq\rho(h)\leq1\)</span> para todo <span class="math inline">\(h\)</span>.</p>
<p>** Propiedades de la función de covarianza**</p>
<ol style="list-style-type: decimal">
<li>Para el valor en <span class="math inline">\(h=0\)</span>, la función de autocovarianza
<span class="math display" id="eq:eq-funcion-autocovarianza-h0">\[\begin{equation}
\gamma(0)=\mathbb{E}[(x_t-\mu)^2]
\tag{2.17}
\end{equation}\]</span>
<p>es la varianza de la serie de tiempo; note que la desigualdad de Cauchy-Schwartz implica que <span class="math inline">\(|\gamma(h)|\leq\gamma(0)\)</span>.</p></li>
<li>La autocovarianza de una serie estacionaria es simétrica respecto al origen, esto es
<span class="math display" id="eq:eq-simetria-funcion-autocovarianza">\[\begin{equation}
\gamma(h)=\gamma(-h)
\tag{2.18}
\end{equation}\]</span>
para todo <span class="math inline">\(h\)</span>. Esta propiedad se debe a que trasladar la serie por <span class="math inline">\(h\)</span> significa que
<span class="math display">\[\begin{eqnarray*}
\gamma(h)&amp;=&amp;\gamma(t+h-t)\\
    &amp;=&amp;\mathbb{E}[(x_{t+h}-\mu)(x_t-\mu)]\\
    &amp;=&amp;\mathbb{E}[(x_t-\mu)(x_{t+h}-\mu)]\\
    &amp;=&amp;\gamma(t-(t+h))\\
    &amp;=&amp;\gamma(-h)
\end{eqnarray*}\]</span>
<p>lo cual muestra como usar la notación para demostrar el resultado.</p></li>
</ol>

<div class="definition">
<span id="def:defi-conjuntamente-estacionarias" class="definition"><strong>Definición 2.11  </strong></span>Dos series de tiempo <span class="math inline">\(x_t\)</span> y <span class="math inline">\(x_s\)</span> se dice que son <strong>conjuntamente estacionarias</strong> si cada una de ellas es estacionaria y la función de correlación cruzada
<span class="math display" id="eq:eq-estacionaridad-conjunta">\[\begin{equation}
\gamma_{xy}(h)=\mathbb{E}[(x_{t+h}-\mu_x)(y_t-\mu_y)]
\tag{2.19}
\end{equation}\]</span>
<p>es una función sólo del salto <span class="math inline">\(h\)</span>.</p>
</div>

<hr />

<div class="definition">
<span id="def:defi-ccf-conjuntamente-estacionarias" class="definition"><strong>Definición 2.12  </strong></span>La <strong>función de correlación cruzada (CCF)</strong> de dos series conjuntamente estacionarias <span class="math inline">\(x_t\)</span> y <span class="math inline">\(y_t\)</span> se define como
<span class="math display" id="eq:eq-ccf-conjuntamente-estacionarias">\[\begin{equation}
\rho_{xy}(h)=\frac{\gamma_{xy}(h)}{\sqrt{\gamma_x(0)\gamma_y(0)}}
\tag{2.20}
\end{equation}\]</span>
</div>

<hr />
De nuevo, tenemos el resultado <span class="math inline">\(-1\leq\rho_{xy}(h)\leq1\)</span> lo cual nos permite comparar los valores extremos -1 y 1 cuando vemos la relación entre <span class="math inline">\(x_{t+h}\)</span> y <span class="math inline">\(y_t\)</span>. La función de correlación cruzada satisface
<span class="math display" id="eq:eq-simetria-ccf-conjuntamente-estacionarias">\[\begin{equation}
\rho_{xy}(h)=\rho_{yx}(-h)
\tag{2.21}
\end{equation}\]</span>
<p>lo cual se puede demostrar de manera similar que para <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-simetria-funcion-autocovarianza">(2.18)</a>.</p>

<div class="example">
<span id="exm:ejem-estacionaridad-conjunta" class="example"><strong>Ejemplo 2.1  (Estacionaridad conjunta)  </strong></span>Considere las series <span class="math inline">\(x_t\)</span> y <span class="math inline">\(y_t\)</span> formadas por las sumas y diferencias de dos valores sucesivos de un ruido blanco respectivamente, esto es <span class="math display">\[x_t=w_t+w_{t-1}\]</span> y <span class="math display">\[y_t=w_t-w_{t-1}\]</span> donde <span class="math inline">\(w_t\)</span> son variables aleatorias independientes con media cero y varianza <span class="math inline">\(\sigma_w^2\)</span>. Es fácil demostrar que <span class="math inline">\(\gamma_x(0)=\gamma_y(0)=2\sigma_w^2\)</span> y <span class="math inline">\(\gamma_x(1)=\gamma_x(-1)=\sigma_w^2\)</span>, <span class="math inline">\(\gamma_y(1)=\gamma_y(-1)=-\sigma_w^2\)</span>. También
<span class="math display">\[\begin{eqnarray*}
\gamma_{xy}(1)&amp;=&amp;\mathbb{E}[(x_{t+1}-0)(y_t-0)]\\
    &amp;=&amp;\mathbb{E}[(w_{t+1}+w_t)(w_t-w_{t-1})]\\
    &amp;=&amp;\sigma_w^2
\end{eqnarray*}\]</span>
<p>porque solo uno de los productos es distinto de cero.\ Similarmente, <span class="math inline">\(\gamma_{xy}(0)=0,\gamma_{xy}(-1)=-\sigma_w^2\)</span>. Usando (), obtenemos <span class="math display">\[\rho_{xy}(h)=\begin{cases}0,&amp;h=0\\
            1/2,&amp;h=1\\
            -1/2,&amp;h=-1\\
            0,&amp;|h|\geq2\end{cases}.\]</span> Claramente, las funciones de autocovarianza y correlación cruzada dependen solo del salto <span class="math inline">\(h\)</span>, por lo tanto las series son conjuntamente estacionarias.</p>
</div>

<hr />
<p>El concepto de estacionaridad débil forma la base para muchos de los análisis realizados con series de tiempo. Las propiedades fundamentales de la media <a href="caracteristicas-de-series-de-tiempo.html#eq:e1p22">(2.13)</a> y la función de covarianza <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-funcion-autocovarianza-estacionaria">(2.15)</a> son satisfechas por muchos modelos teóricos que aparecen para generar realizaciones muestrales apropiadas.</p>

<div class="definition">
<span id="def:defi-proceso-lineal" class="definition"><strong>Definición 2.13  </strong></span>Un <strong>proceso lineal</strong> <span class="math inline">\(x_t\)</span> se define como una combinación lineal de variables aleatorias de ruido blanco <span class="math inline">\(w_t\)</span>, y está dado por
<span class="math display" id="eq:eq-proceso-lineal">\[\begin{equation}
x_t=\mu+\sum_{j=-\infty}^{\infty}\psi_jw_{t-j}
\tag{2.22}
\end{equation}\]</span>
donde los coeficientes satisfacen
<span class="math display" id="eq:eq-coeficientes-proceso-lineal">\[\begin{equation}
\sum_{j=-\infty}^{\infty}|\psi_j|&lt;\infty
\tag{2.23}
\end{equation}\]</span>
</div>

<hr />
Para un proceso lineal, podemos demostrar que la función de autocovarianza está dada por
<span class="math display" id="eq:eq-funcion-autocovarianza-proceso-lineal">\[\begin{equation}
\gamma(h)=\sigma_w^2\sum_{j=-\infty}^{\infty}\psi_{j+h}\psi_j
\tag{2.24}
\end{equation}\]</span>
<p>para todo <span class="math inline">\(h\geq0\)</span>; recuerde que <span class="math inline">\(\gamma(-h)=\gamma(h)\)</span>. Finalmente como mencionamos anteriormente, un caso importante en el cual una serie débilmente estacionaria es también estrictamente estacionaria es la serie normal o gaussiana.</p>

<div class="definition">
<p><span id="def:defi-proceso-gaussiano" class="definition"><strong>Definición 2.14  </strong></span>Un proceso <span class="math inline">\(\{x_t\}\)</span>, se dice que es un <strong>proceso gaussiano</strong> si el <span class="math inline">\(k\)</span>-ésimo vector dimensional <span class="math inline">\(\hat{x}=(x_{t_1},x_{t_2},\ldots,x_{t_k})\)</span>, para cada conjunto de puntos <span class="math inline">\(t_1,t_2,\ldots,t_k\)</span> y cada entero positivo <span class="math inline">\(k\)</span> tiene distribución normal multivariada.</p>
</div>

<hr />
Definiendo <span class="math inline">\(k\times1\)</span> vector de medias <span class="math inline">\(\hat{\mu}=(\mu_{t_1},\mu_{t_2},\ldots,\mu_{t_k})&#39;\)</span> y la <span class="math inline">\(k\times k\)</span> matriz de covarianza positiva como <span class="math inline">\(\Gamma=\{\gamma(t_i,t_j);i,j=1,\ldots,k\}\)</span>, la función de densidad normal multivariada se puede escribir como
<span class="math display" id="eq:eq-densidad-normal-multivariada">\[\begin{equation}
f(\hat{x})=(2\pi)^{-k/2}|\Gamma|^{-1/2}\exp\left\{-\frac{1}{2}(\hat{x}-\hat{\mu})&#39;\Gamma^{-1}(\hat{x}-\hat{\mu})\right\}
\tag{2.25}
\end{equation}\]</span>
<p>donde <span class="math inline">\(|\cdot|\)</span> denota el determinante. Esta distribución forma la base para resolver problemas que envuelven inferencia estadística para series de tiempo. Si una serie de tiempo gaussiana <span class="math inline">\(\{x_t\}\)</span> es débilmente estacionaria, entonces <span class="math inline">\(\mu_t=\mu\)</span> y <span class="math inline">\(\gamma(t_i,t_j)=\gamma(|t_i-t_j|)\)</span>, de modo que el vector <span class="math inline">\(\hat{\mu}\)</span> y la matriz <span class="math inline">\(\Gamma\)</span> son independientes del tiempo. Este hecho implica que todas las distribuciones finitas, <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-densidad-normal-multivariada">(2.25)</a> de la serie <span class="math inline">\(\{x_t\}\)</span> dependen sólo del salto de tiempo y no del tiempo actual, y por consiguiente la serie debe ser estrictamente estacionaria.</p>
</div>
<div id="estimacion-de-la-tendencia" class="section level2">
<h2><span class="header-section-number">2.2</span> Estimación de la Tendencia</h2>
<p>En esta sección introducimos los métodos para la estimación de la tendencia. En esencia, existen dos métodos para estimar la tendencia y la componente estacional de una serie de tiempo:</p>
<ul>
<li><p><strong>Método paramétrico</strong>: Se basa en</p></li>
<li><p>Proponer modelos paramétricos para expresar la relación que guardan la tendencia y la componente estacional con el tiempo.</p></li>
<li><p>Ajustar dichos modelos a la serie de tiempo (por ejemplo, a través del método de mínimos cuadrados).</p></li>
<li><p>Aislar la tendencia y la componente estacional por medio de los modelos ajustados.</p></li>
<li><p><strong>Método no paramétrico</strong>: Se basa en</p></li>
<li><p>Asumir “suavidad” en la relación que guardan la tendencia y la componente estacional con el tiempo.</p></li>
<li><p>Aislar la tendencia y la componente estacional a través de la suavización del gráfico de la serie (aplicando, por ejemplo, filtros de promedios móviles).</p></li>
</ul>
<p>Hay otros métodos que no consideraremos en este libro, por ejemplo, <em>wavelets</em>. En ocasiones la expresión “suavizar una serie” es equivalente a “extracción de la tendencia de una serie”, y ambas equivalen a la estimación de la tendencia.</p>
<p>A continuación presentamos una lista de posibles modelos para la tendencia <span class="math inline">\(T_t\)</span>:</p>
<ul>
<li>Lineal
<span class="math display" id="eq:eq-modelo-lineal">\[\begin{equation}
T_t=\beta_0+\beta_1t
\tag{2.26}
\end{equation}\]</span></li>
<li>Cuadrático
<span class="math display" id="eq:eq-modelo-cuadratico">\[\begin{equation}
T_t=\beta_0+\beta_1t+\beta_2t^2
\tag{2.27}
\end{equation}\]</span></li>
<li>Cúbico
<span class="math display" id="eq:eq-modelo-cubico">\[\begin{equation}
T_t=\beta_0+\beta_1t+\beta_2t^2+\beta_3t^3
\tag{2.28}
\end{equation}\]</span></li>
<li>Exponencial
<span class="math display" id="eq:eq-modelo-exponencial">\[\begin{equation}
T_t=\exp(\beta_0+\beta_1t)
\tag{2.29}
\end{equation}\]</span></li>
<li>Logístico
<span class="math display" id="eq:eq-modelo-logistico">\[\begin{equation}
T_t=\frac{\beta_2}{1+\beta_1\exp(-\beta_0t)}
\tag{2.30}
\end{equation}\]</span></li>
</ul>
<p>En la tendencia cuadrática podemos observar:</p>
<ul>
<li>Si <span class="math inline">\(\beta_1,\beta_2&gt;0\)</span>, <span class="math inline">\(T_t\)</span> es monótona creciente.</li>
<li>Si <span class="math inline">\(\beta_1,\beta_2&lt;0\)</span>, <span class="math inline">\(T_t\)</span> es monótona decreciente.</li>
<li>Si <span class="math inline">\(\beta_1&gt;0\)</span> y <span class="math inline">\(\beta_2&lt;0\)</span>, <span class="math inline">\(T_t\)</span> es cóncava.</li>
<li>Si <span class="math inline">\(\beta_1&lt;0\)</span> y <span class="math inline">\(\beta_2&gt;0\)</span>, <span class="math inline">\(T_t\)</span> es convexa.</li>
</ul>
<p>Otro modelo propuesto para la tendencia es el dado por la siguiente definición.</p>

<div class="definition">
<span id="def:defi-modelo-log-lineal" class="definition"><strong>Definición 2.15  </strong></span>El modelo <strong>Logarítmico Lineal</strong> o <strong>Log-Lineal</strong> se define como
<span class="math display" id="eq:eq-modelo-log-lineal">\[\begin{equation}
\ln X_t = \beta_0+\beta_1t + \epsilon_t
\tag{2.31}
\end{equation}\]</span>
</div>

<hr />
<p>El modelo anterior corresponde a un modelo con tendencia lineal para el logaritmo de <span class="math inline">\(X_t\)</span>. En <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-log-lineal">(2.31)</a> al tomar exponencial se tiene <span class="math inline">\(X_t = \exp(\beta_0+\beta_1t + \epsilon_t)\)</span>, que es similar al modelo con tendencia exponencial <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-exponencial">(2.29)</a>. Sin embargo, son modelos diferentes y se estiman por métodos diferentes.</p>
<p>Para la estimación de los parámetros <span class="math inline">\(\beta_0,\beta_1,\beta_2\)</span> en los modelos lineales <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-lineal">(2.26)</a>, <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-cuadratico">(2.27)</a>, <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-cubico">(2.28)</a> y <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-log-lineal">(2.31)</a> utilizaremos el método de mínimos cuadrados clásico (MCC). En este método los parámetros estimados son aquellos que producen el valor mínimo de la suma de errores cuadrados. Para los modelos <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-exponencial">(2.29)</a> y <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-logistico">(2.30)</a> se usa el método de mínimos cuadrados no lineales, que también minimiza la suma de errores cuadrados.</p>
<p>El modelo Log-Lineal <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-log-lineal">(2.31)</a> es equivalente, algebráicamente, a <span class="math display">\[X_t = \exp(\beta_0 + \beta_1t + \epsilon_t).\]</span> Sin embargo, este último modelo es no lineal y no coincide con el modelo exponencial,<a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-exponencial">(2.29)</a>, <span class="math inline">\(X_t = \exp(\beta_0+\beta_1t)+\epsilon_t\)</span>. Es posible estimar por mínimos cuadrados ordinarios el modelo Log-Lineal y utilizar los parámetros estimados <span class="math inline">\(\hat{\beta}_0,\hat{\beta}_1\)</span> como valores iniciales en la estimación del modelo exponencial por mínimos cuadrados no lineales. Pero los parámetros estimados en ambos modelos no necesariamente coinciden.</p>
<p>Aunque la serie tenga una componente estacional <span class="math inline">\(E_t\)</span>, <span class="math inline">\(X_t = T_t + E_t + \epsilon_t\)</span>, solamente consideramos un modelo de regresión entre <span class="math inline">\(X_t\)</span> y <span class="math inline">\(T_t\)</span>, tal que <span class="math inline">\(X_t = T_t + \eta_t\)</span>, donde <span class="math inline">\(\eta_t\)</span> es el término de error, de forma que <span class="math inline">\(\eta_t=E_t+\epsilon_t\)</span>. Por ejemplo,</p>
<ol style="list-style-type: decimal">
<li>En el caso lineal <span class="math inline">\(T_t = \beta_0 + \beta_1t\)</span>, ajustamos el modelo de regresión lineal: <span class="math inline">\(X_t = \beta_0 + \beta_1t + \eta_t\)</span>.</li>
<li>En el caso cuadrático <span class="math inline">\(T_t = \beta_0 +\beta_1t+\beta_2t^2\)</span>, ajustamos el modelo de regresión cuadrático <span class="math inline">\(X_t = \beta_0+\beta_1t+\beta_2t^2 +\eta_t\)</span>. Nótese que en este caso hay que definir una variable explicativa adicional <span class="math inline">\(t^2\)</span>.</li>
</ol>
<p>En general, para que datos de series de tiempo sean estacionarias, es necesario hacer un promedio de productos en el tiempo. Como para datos de serie de tiempo es importante medir la dependencia entre los valores de la serie; al menos, debemos ser capaces de estimar las autocorrelaciones con precisión. Será difícil medir la dependencia de estos valores si la estructura de dependencia no es regular o si cambia en el tiempo. De ahí, que para realizar cualquier análisis estadístico significativo de datos de series de tiempo, será crucial que las funciones de media y autocovarianza satisfagan las condiciones de estacionaridad dadas en la Definición <a href="#def:defi-debil-estacionaria"><strong>??</strong></a>. A menudo, este no es el caso, y en esta sección daremos algunos métodos para lidiar con los efectos de no-estacionaridad sobre las propiedades estacionarias de las series a estudiar.</p>
<p>Quizás la forma más fácil de trabajar con series no-estacionarias es el modelo de tendencia estacionaria donde el proceso tiene comportamiento estacionario alrededor de una tendencia. Podemos escribir este tipo de modelos como</p>
<span class="math display" id="eq:eq-modelo-tendencia-estacionaria">\[\begin{equation}
X_t=T_t+Y_t
\tag{2.32}
\end{equation}\]</span>
<p>donde <span class="math inline">\(X_t\)</span> son las observaciones, <span class="math inline">\(T_t\)</span> denota la tendencia y <span class="math inline">\(Y_t\)</span> es un proceso estacionario.</p>
<p>Por lo general, una tendencia fuerte <span class="math inline">\(T_t\)</span> puede oscurecer el comportamiento del proceso estacionario <span class="math inline">\(Y_t\)</span>, como veremos en ejemplos posteriores. De aquí, será una ventaja el que podamos remover la tendencia como un primer paso para un análisis exploratorio de los datos. Los pasos envuelven obtener un estimador razonable del componente de tendencia, llamémoslo <span class="math inline">\(\hat{T}_t\)</span> y entonces trabajar con el residual</p>
<span class="math display" id="eq:eq-estimacion-componente-tendencia">\[\begin{equation}
\hat{Y}_t=X_t-\hat{T}_t.
\tag{2.33}
\end{equation}\]</span>
<p>El primer paso en el análisis de cualquier tipo de serie es un gráfico de los datos.</p>
<ul>
<li><p>Si existe alguna aparente discontinuidad en la serie, tal como un cambio súbito en el nivel de la serie, esto puede darnos una idea para el análisis de la serie, un primer paso sería dividir la serie en segmentos homogéneos.</p></li>
<li><p>Si existen observaciones o datos “<em>outliers</em>”, estos deben ser estudiados con cuidado para verificar si existe alguna justificación para descartar estas observaciones, como por ejemplo si una observación ha sido registrada de algún otro proceso por error.</p></li>
<li><p>La inspección del gráfico también podría sugerir la representación de los datos como una realización de un proceso, como el modelo clásico de descomposición dado por <a href="introduccion.html#eq:eq-modelo-aditivo">(1.8)</a>.</p></li>
</ul>
<p>Si la componente estacional y la componente aleatoria o ruido parecen incrementarse con el nivel del proceso entonces una transformación preliminar de los datos es a menudo usada para hacer que los datos transformados sean compatibles con el modelo <a href="introduccion.html#eq:eq-modelo-aditivo">(1.8)</a>. En esta sección discutiremos algunas técnicas para identificar y eliminar las componentes en <a href="introduccion.html#eq:eq-modelo-aditivo">(1.8)</a>.</p>
<p>Nuestro objetivo es estimar y extraer las componentes determinísticas <span class="math inline">\(T_t\)</span> y <span class="math inline">\(E_t\)</span> con la esperanza de que el residual o la componente aleatoria <span class="math inline">\(\epsilon_t\)</span> llegue a ser un proceso estacionario. Entonces podremos usar la teoría de tales procesos para hallar un modelo probabilístico satisfactorio para el proceso <span class="math inline">\(\epsilon_t\)</span>, analizar sus propiedades y usarlo en conjunto con <span class="math inline">\(T_t\)</span> y <span class="math inline">\(E_t\)</span> para hacer pronósticos y control de <span class="math inline">\(X_t\)</span>.</p>
<p>Los dos enfoques para la eliminación de las componentes de tendencia y estacional son:</p>
<ol style="list-style-type: decimal">
<li>Estimación de <span class="math inline">\(T_t\)</span> y <span class="math inline">\(E_t\)</span> en el modelo <a href="introduccion.html#eq:eq-modelo-aditivo">(1.8)</a>,</li>
<li>Diferencia de los datos <span class="math inline">\(X_t\)</span>.</li>
</ol>
<p>Ilustraremos ambos enfoque con varios ejemplos</p>
<div id="estimacion-de-la-tendencia-en-ausencia-de-estacionalidad" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Estimación de la tendencia en ausencia de estacionalidad</h3>
Si tenemos una serie de tiempo para la cual está ausente la componente estacional <span class="math inline">\(E_t\)</span> el modelo <a href="introduccion.html#eq:eq-modelo-aditivo">(1.8)</a> llega ser
<span class="math display" id="eq:eq-modelo-tendencia">\[\begin{equation}
X_t = T_t + \epsilon_t,\quad t=1,\ldots,n
\tag{2.34}
\end{equation}\]</span>
<p>donde, sin perdida de generalidad, podemos suponer que <span class="math inline">\(\mathbb{E}(\epsilon_t)=0\)</span>. A continuación vamos a describir tres métodos para estimar la tendencia <span class="math inline">\(T_t\)</span>.</p>
<ol style="list-style-type: decimal">
<li><strong>Método T1: Estimación de <span class="math inline">\(T_t\)</span> por mínimos cuadrados</strong>. El objetivo de este método es intentar ajustar una familia paramétrica de funciones como las vistas en las ecuaciones <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-lineal">(2.26)</a> a <a href="#eq:">(<strong>??</strong>)</a>, a los datos eligiendo los parámetros que minimicen <span class="math inline">\(\sum_t(X_t-T_t)^2\)</span>. Esto es, asumiendo que $(_t)=0, se tiene <span class="math display">\[\mathbb{E}(X_t)=T_t=f(t)\]</span> Una suposición común es que la función <span class="math inline">\(f\)</span> depende de ciertos parámetros (desconocidos) <span class="math inline">\(\beta_1,\ldots,\beta_p\)</span>, es decir,
<span class="math display" id="eq:eq-funcion-parametros-metodo-T1">\[\begin{equation}
f(t)=f(t;\beta_1,\ldots,\beta_p)
\tag{2.35}
\end{equation}\]</span>
Sin embargo, el <em>tipo</em> de función es conocida. Los parámetros <span class="math inline">\(\beta_1,\ldots,\beta_p\)</span> serán estimados a partir de una realización <span class="math inline">\(x_t\)</span> de la variable aleatoria <span class="math inline">\(X_t\)</span>. La aproximación por <em>estimación de mínimos cuadrados</em> <span class="math inline">\(\hat{\beta}_1,\ldots,\hat{\beta}_p\)</span> debe satisfacer
<span class="math display" id="eq:ecuacion-minimos-cuadrados-T1">\[\begin{equation}
\sum_t(x_t-f(t;\hat{\beta}_1,\ldots,\hat{\beta}_p))^2 = \min_{\beta_1,\ldots,\beta_p}\sum_t(x_t-f(t;\beta_1,\ldots,\beta_p))^2
\tag{2.36}
\end{equation}\]</span>
cuya solución, si existe, es un problema numérico. El valor <span class="math inline">\(\hat{x}_t=f(t;\hat{\beta}_1,\ldots,\hat{\beta}_p)\)</span> servirá como una <em>predicción</em> de futuros valores <span class="math inline">\(x_t\)</span>. Las diferencias observadas <span class="math inline">\(x_t-\hat{x}_t\)</span> son llamadas <em>residuales</em>. Ellas contienen información sobre la bondad de ajuste del modelo a los datos.</li>
</ol>

<div class="example">
<span id="exm:ejem-poblacion-usa-metodo-T1" class="example"><strong>Ejemplo 2.2  </strong></span>El archivo “USPOP.txt” contiene la información de la población de Estados Unidos de América desde 1780 hasta 1980 segun el censo poblacional cada 10 años. En el gráfico podemos observar que no existe estacionalidad, por lo que podemos aplicar el método descrito para ajustar la tendencia.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">uspop=<span class="kw">ts</span>(<span class="kw">scan</span>(<span class="st">&quot;data/USPOP.txt&quot;</span>),<span class="dt">frequency=</span><span class="dv">1</span><span class="op">/</span><span class="dv">10</span>,<span class="dt">start=</span><span class="dv">1790</span>) 
pop=<span class="kw">window</span>(uspop,<span class="dt">start=</span><span class="dv">1790</span>)
<span class="kw">plot</span>(pop,<span class="dt">type=</span><span class="st">&quot;o&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Poblacion (millones)&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-21-1.svg" /><!-- --></p>
<p>Podemos notar del gráfico que la tendencia es creciente y parece tener un comportamiento cuadrático, por lo que ajustando una función de la forma <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-cuadratico">(2.27)</a> para la población de los datos USPOP para <span class="math inline">\(1790\leq t\leq1980\)</span> nos da los parámetros estimados</p>
<p><span class="math display">\[\hat{a}_0=2.101\times10^{10};\quad \hat{a}_1=-2.338\times10^{7}; \hat{a}_2=6.506\times10^{3}.\]</span></p>
<p>En el gráfico siguiente se puede observar la curva ajustada y los datos originales. Los valores estimados del proceso de ruido <span class="math inline">\(\epsilon_t, 1790\leq t\leq1980\)</span>, son los residuales obtenidos por sustracción de <span class="math inline">\(\hat{T}_t=\hat{a}_0+\hat{a}_1t+\hat{a}_2t^2\)</span> de la serie <span class="math inline">\(X_t\)</span>. La componente de tendencia <span class="math inline">\(T_t\)</span> nos proporciona un predictor natural de los valores futuros de <span class="math inline">\(X_t\)</span>. Por ejemplo si deseamos estimar <span class="math inline">\(T_{1990}\)</span> por su valor medio, obtenemos</p>
<p><span class="math display">\[T_{1990} = 2.4853\times10^8\]</span></p>
<p>para la población de EE.UU en 1990. Sin embargo si los residuales <span class="math inline">\(\hat{\epsilon}_t\)</span> están altamente correlacionados podemos ser capaces de usar esos valores para dar una mejor estimación de <span class="math inline">\(T_{1990}\)</span> y por consiguiente de <span class="math inline">\(X_{1990}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x=<span class="kw">time</span>(pop)
reg=<span class="kw">lm</span>(pop<span class="op">~</span>x<span class="op">+</span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>),<span class="dt">na.action=</span><span class="ot">NULL</span>)
<span class="kw">summary</span>(reg)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = pop ~ x + I(x^2), na.action = NULL)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -6947521  -358167   436285  1481410  3391761 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.10e+10   6.59e+08    31.9   &lt;2e-16 ***
## x           -2.34e+07   6.98e+05   -33.5   &lt;2e-16 ***
## I(x^2)       6.51e+03   1.85e+02    35.2   &lt;2e-16 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2770000 on 18 degrees of freedom
## Multiple R-squared:  0.999,  Adjusted R-squared:  0.999 
## F-statistic: 8.05e+03 on 2 and 18 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(pop,<span class="dt">type=</span><span class="st">&quot;o&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Años&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Poblacion (millones)&quot;</span>)
<span class="kw">lines</span>(reg<span class="op">$</span>fitted.values,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-22-1.svg" /><!-- --></p>
<hr />

<div class="example">
<span id="exm:ejemplo-poblacion-alemania-T1" class="example"><strong>Ejemplo 2.3  </strong></span>El archivo “Population-North-Rhine-Westphalia.txt” contiene la población de la región North-Rhine-Westphalia (Alemania) en millónes cada 5 años desde 1935 hasta 1980. Observando el gráfico podemos suponer que la tendencia se puede ajustar por el modelo cúbico <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-cubico">(2.28)</a>, esto es <span class="math display">\[T_t=\beta_0+\beta_1t+\beta_2t^2+\beta_3t^3\]</span> El código en R para el gráfico y el ajuste es
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NRWpop=<span class="kw">read.table</span>(<span class="st">&quot;data/Population-North-Rhine-Westphalia.txt&quot;</span>,
                     <span class="dt">header =</span> <span class="ot">TRUE</span>)
knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">head</span>(NRWpop,<span class="dt">booktabs=</span><span class="ot">TRUE</span>,
                  <span class="dt">caption=</span><span class="st">&quot;Población (en millones) de North-Rhine-Westphalia, Alemania, 1935-1980&quot;</span>))</code></pre></div>
<table>
<thead>
<tr>
<th style="text-align:right;">
Year
</th>
<th style="text-align:right;">
Population
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1935
</td>
<td style="text-align:right;">
11772
</td>
</tr>
<tr>
<td style="text-align:right;">
1940
</td>
<td style="text-align:right;">
12059
</td>
</tr>
<tr>
<td style="text-align:right;">
1945
</td>
<td style="text-align:right;">
11200
</td>
</tr>
<tr>
<td style="text-align:right;">
1950
</td>
<td style="text-align:right;">
12926
</td>
</tr>
<tr>
<td style="text-align:right;">
1955
</td>
<td style="text-align:right;">
14442
</td>
</tr>
<tr>
<td style="text-align:right;">
1960
</td>
<td style="text-align:right;">
15694
</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(NRWpop, <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Años&quot;</span>,<span class="dt">ylab =</span> <span class="st">&quot;Población (millones)&quot;</span>)
<span class="co"># Modelo cúbico</span>
t=NRWpop[,<span class="dv">1</span>]
pob=NRWpop[,<span class="dv">2</span>]
modelo=<span class="kw">lm</span>(pob<span class="op">~</span>t<span class="op">+</span><span class="kw">I</span>(t<span class="op">^</span><span class="dv">2</span>)<span class="op">+</span><span class="kw">I</span>(t<span class="op">^</span><span class="dv">3</span>),<span class="dt">na.action =</span> <span class="ot">NULL</span>)
<span class="kw">summary</span>(modelo)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = pob ~ t + I(t^2) + I(t^3), na.action = NULL)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -813.0 -199.2   67.1  275.6  493.8 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  2.11e+09   5.10e+08    4.13   0.0061 **
## t           -3.23e+06   7.81e+05   -4.14   0.0061 **
## I(t^2)       1.65e+03   3.99e+02    4.14   0.0061 **
## I(t^3)      -2.81e-01   6.79e-02   -4.14   0.0061 **
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 472 on 6 degrees of freedom
## Multiple R-squared:  0.974,  Adjusted R-squared:  0.962 
## F-statistic: 76.2 on 3 and 6 DF,  p-value: 3.63e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lines</span>(t,modelo<span class="op">$</span>fitted.values,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-23-1.svg" /><!-- --> La curva punteada en azul corresponde a los datos originales, la curva en rojo corresponde al ajuste mediante el modelo cúbico.</p>
<hr />
<ol start="2" style="list-style-type: decimal">
<li><strong>Método T2: Suavizado por medio de un promedio móvil</strong>. Sea <span class="math inline">\(q\)</span> un entero no negativo y consideremos un promedio móvil de la forma
<span class="math display" id="eq:eq-promedio-movil-orden-q">\[\begin{equation}
W_t = \frac{1}{2q+1}\sum_{j=-q}^{q}X_{t+j}
\tag{2.37}
\end{equation}\]</span>
de un proceso <span class="math inline">\(\{X_t\}\)</span> definido por <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-tendencia">(2.34)</a>. Entonces para <span class="math inline">\(q+1\leq t\leq n-q\)</span>,
<span class="math display" id="eq:eq-media-promedio-movil">\[\begin{eqnarray}
W_t &amp;=&amp; \frac{1}{2q+1}\sum_{j=-q}^qT_{t+j}+\frac{1}{2q+1}\sum_{j=-q}^q\epsilon_{t+j}\\ \nonumber
&amp;\simeq&amp; T_t \tag{2.38}
\end{eqnarray}\]</span>
suponiendo que <span class="math inline">\(T_t\)</span> es aproximadamente lineal sobre el intervalo <span class="math inline">\([t-q,t+q]\)</span> y que el promedio del término de error sobre este intervalo es cercano a cero.</li>
</ol>
El promedio móvil entonces nos provee con el estimador
<span class="math display" id="eq:eq-estimador-promedio-movil">\[\begin{equation}
\hat{T}_t = \frac{1}{2q+1}\sum_{j=-q}^qX_{t+j},\quad q+1\leq t\leq n-q.
\tag{2.39}
\end{equation}\]</span>
<p>Dado que <span class="math inline">\(X_t\)</span> es no observado para <span class="math inline">\(t\leq0\)</span> o <span class="math inline">\(t\geq n\)</span> no podemos usar <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estimador-promedio-movil">(2.39)</a> para <span class="math inline">\(t\leq q\)</span> o <span class="math inline">\(t&gt;n-q\)</span>. Una forma de resolver este problema es haciendo <span class="math inline">\(X_t=X_1\)</span> para <span class="math inline">\(t&lt;1\)</span> y <span class="math inline">\(X_t=X_n\)</span> para <span class="math inline">\(t&gt;n\)</span>. A continuación presentamos un ejemplo</p>

<div class="example">
<p><span id="exm:ejem-huelgas-USA-T2" class="example"><strong>Ejemplo 2.4  </strong></span>El gráfico siguiente muestra las huelgas ocurridas en EE.UU, de 1951 a 1980, según la Oficina de Estadísticas Laborales del Departamento de Trabajo de los EE.UU.</p>
<p>A estos datos le aplicamos un promedio móvil de 5 puntos, la Figura muestra la serie suavizada y el término de error estimado <span class="math inline">\(\hat{\epsilon}_t = X_t - \hat{T}_t\)</span> se muestra en la Figura . Como era de esperarse ellos no presentan una tendencia clara.</p>
Las instrucciones en R para el suavizado y los gráficos son los siguientes:
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">H=<span class="kw">read.table</span>(<span class="st">&quot;data/Huelgas.txt&quot;</span>)
<span class="co"># Promedio móvil por medio de la función &quot;filter&quot;</span>
W=<span class="kw">filter</span>(H[,<span class="dv">2</span>],<span class="dt">sides=</span><span class="dv">2</span>,<span class="kw">rep</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">5</span>,<span class="dv">5</span>))
<span class="co"># Residuales de X_t</span>
y=H[,<span class="dv">2</span>]<span class="op">-</span>W 
<span class="co"># Graficos</span>
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">1</span>))
<span class="kw">plot</span>(H,<span class="dt">xlab=</span><span class="st">&quot;años&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Huelgas&quot;</span>,<span class="dt">type=</span><span class="st">&#39;b&#39;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Huelgas en EE.UU., años 1951-1980&quot;</span>)
<span class="kw">plot</span>(H[,<span class="dv">1</span>],W,<span class="dt">xlab=</span><span class="st">&quot;años&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Huelgas&quot;</span>,<span class="dt">type=</span><span class="st">&#39;b&#39;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Promedio móvil de 5 puntos para los datos de Huelga&quot;</span>)
<span class="kw">plot</span>(H[,<span class="dv">1</span>],y,<span class="dt">xlab=</span><span class="st">&quot;años&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Residuales&quot;</span>,<span class="dt">type=</span><span class="st">&#39;b&#39;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Residuales e_t=X_t-T_t&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-24-1.svg" /><!-- --></p>
<hr />
Para cada valor fijo <span class="math inline">\(a\in[0,1]\)</span>, el promedio móvil de un lado <span class="math inline">\(\hat{T}_t, t=1,\ldots,n\)</span>, definido por la recursión
<span class="math display" id="eq:eq-promedio-movil-1-lado-peso">\[\begin{equation}
  \hat{T}_t = aX_t+(1-a)\hat{T}_t,\quad t=2,\ldots,n
 \tag{2.40}
\end{equation}\]</span>
<p>y <span class="math display">\[\hat{T}_1=X_1,\]</span> se puede calcular usando la opción <em>sides=1</em> en la función <em>filter</em> de R.</p>
<p>Es usual pensar como aplicación de la ecuación <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-promedio-movil-1-lado-peso">(2.40)</a> como un suavizado exponencial, dado que se sigue de la recursión que para <span class="math inline">\(t\leq2, \hat{T}_t=\sum_{j=0}^{t-2}a(1-a)^jX_{t-j}+(1-a)^{t-1}X_1\)</span>, es un promedio móvil con peso de <span class="math inline">\(X_t,X_{t-1},\ldots\)</span>, con pesos decreciendo exponencialmente (excepto para el último término).</p>
<p>Es útil pensar en <span class="math inline">\(\{\hat{T}_t\}\)</span> en (<em>filter</em>) como un proceso obtenido de <span class="math inline">\(\{X_t\}\)</span> por aplicación de un operador lineal o filtro lineal <span class="math inline">\(\hat{T}_t=\sum_{j=-\infty}^{\infty}a_jX_{t+j}\)</span> con pesos <span class="math inline">\(a_j=(2q+1)^{-1},-q\leq j\leq q\)</span>, y <span class="math inline">\(a_j=0,|j|&gt;q\)</span>. Este filtro particular es un filtro de “paso-bajo” ya que toma los datos <span class="math inline">\(\{X_t\}\)</span> y remueve la componente de rápida fluctuación (o de alta frecuencia) <span class="math inline">\(\{\hat{\epsilon}_t\}\)</span>, para dejar el término de la tendencia estimada de lenta variación <span class="math inline">\(\{\hat{T}_t\}\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Método T3: Diferenciación para generar datos estacionarios</strong>. En lugar de intentar remover el ruido por suavizado como en el Método T2, ahora intentaremos eliminar la tendencia por diferenciación. Definamos primero el operador diferencia <span class="math inline">\(\nabla\)</span> por
<span class="math display" id="eq:eq-operador-diferencia">\[\begin{equation}
  \nabla x_t = x_t-x_{t-1}=(1-B)x_t,
\tag{2.41}
\end{equation}\]</span>
donde <span class="math inline">\(B\)</span> es el operador de desplazamiento hacia atrás (<em>backward shift operator</em> en inglés) u operador de cambio
<span class="math display" id="eq:eq-backward-shift-operator">\[\begin{equation}
  Bx_t=x_{t-1}.
\tag{2.42}
\end{equation}\]</span>
Las potencias de los operadores <span class="math inline">\(B\)</span> y <span class="math inline">\(\nabla\)</span> se definen de manera obvia, esto es, <span class="math inline">\(B^j(x_t)=x_{t-j}\)</span> y <span class="math inline">\(\nabla^j(x_t)=\nabla(\nabla^{j-1}(x_t)),j\geq1\)</span> con <span class="math inline">\(\nabla^0(x_t)=x_t\)</span>. Los polinomios en <span class="math inline">\(B\)</span> y <span class="math inline">\(\nabla\)</span> se manipulan de la misma manera que las funciones polinómicas de variables reales. Por ejemplo
<span class="math display">\[\begin{eqnarray*}
  \nabla^2x_t &amp;=&amp; \nabla(\nabla x_t) = (1-B)(1-B)x_t = (1-2B+B^2)x_t \\
          &amp;=&amp; x_t-2x_{t-1}+x_{t-2}.
\end{eqnarray*}\]</span>
Si el operador <span class="math inline">\(\nabla\)</span> se aplica a una función con tendencia lineal <span class="math inline">\(T_t=at+b\)</span>, entonces obtenemos la función constante <span class="math inline">\(\nabla T_t=a\)</span>. De la misma manera cada tendencia polinomial de grado <span class="math inline">\(k\)</span> se puede reducir a una constante por aplicación del operador <span class="math inline">\(\nabla^k\)</span>.</li>
</ol>
<p>Iniciando entonces con el modelo <span class="math inline">\(X_t=T_t+\epsilon_t\)</span>, donde <span class="math inline">\(T_t=\sum_{j=0}^ka_jt^j\)</span> y <span class="math inline">\(\epsilon_t\)</span> es estacionario con media cero, obtenemos <span class="math display">\[\nabla^kX_t = k!a_k+\nabla^k\epsilon_t,\]</span> un proceso estacionario con media <span class="math inline">\(k!a_k\)</span>. Esta consideración sugiere la posibilidad, dada una sucesión <span class="math inline">\(\{X_t\}\)</span> de datos, de aplicar el operador <span class="math inline">\(\nabla\)</span> repetidamente hasta conseguir una sucesión <span class="math inline">\(\{\nabla^kX_t\}\)</span> la cual puede ser apropiadamente modelada como una realización de un proceso estacionario. Se encuentra a menudo en la práctica que el orden <span class="math inline">\(k\)</span> de diferenciación es bastante pequeño, frecuentemente uno o dos.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>

<div class="example">
<p><span id="exm:ejem-diferenciacion-poblacion-usa-T2" class="example"><strong>Ejemplo 2.5  </strong></span>Aplicando esta técnica al ejemplo <a href="caracteristicas-de-series-de-tiempo.html#exm:ejem-poblacion-usa-metodo-T1">2.2</a> de población de los EE.UU, hallamos que dos operaciones de diferenciación son suficientes para producir una serie sin aparente tendencia. Los datos diferenciados se muestran en la Figura. Note que la magnitud de las fluctuaciones en <span class="math inline">\(\nabla^2X_n\)</span> se incrementa con el valor de <span class="math inline">\(n\)</span>. Este efecto se puede suprimir tomando primero logaritmo natural, <span class="math inline">\(y_n=\ln X_n\)</span> y entonces aplicando el operador <span class="math inline">\(\nabla^2\)</span> a la serie <span class="math inline">\(\{y_n\}\)</span>.</p>
Las instrucciones en R son las siguientes:
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Dx=<span class="kw">diff</span>(uspop,<span class="dt">difference=</span><span class="dv">2</span>)
<span class="kw">plot</span>(Dx,<span class="dt">type=</span><span class="st">&quot;b&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Año&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Diferencias&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-25-1.svg" /><!-- --></p>
<hr />
</div>
<div id="estimacion-de-la-tendencia-y-la-estacionalidad" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Estimación de la tendencia y la estacionalidad</h3>
Los métodos descritos para estimar y remover la tendencia pueden ser adaptados de manera natural para estimar tanto la tendencia como la estacionalidad en el modelo general
<span class="math display">\[\begin{equation}
X_t = T_t + E_t + \epsilon_t
\end{equation}\]</span>
<p>donde <span class="math inline">\(\mathbb{E}(\epsilon_t)=0, E_{t+d}=E_t\)</span> y <span class="math inline">\(\sum_{j=1}^dE_t=0\)</span>. Ilustraremos estos métodos con referencia al siguiente ejemplo de accidentes. El archivo “Accidentes3.txt” muestra el número de accidentes mortales de automóviles mensual ocurridos en EE.UU., entre los años 1973 y 1978. En la tabla siguiente se muestran los datos</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X&lt;-<span class="kw">read.table</span>(<span class="st">&quot;data/Accidentes3.txt&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)</code></pre></div>
<table>
<thead>
<tr>
<th style="text-align:left;">
Mes
</th>
<th style="text-align:right;">
X1973
</th>
<th style="text-align:right;">
X1974
</th>
<th style="text-align:right;">
X1975
</th>
<th style="text-align:right;">
X1976
</th>
<th style="text-align:right;">
X1977
</th>
<th style="text-align:right;">
X1978
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Ene
</td>
<td style="text-align:right;">
9007
</td>
<td style="text-align:right;">
7750
</td>
<td style="text-align:right;">
8162
</td>
<td style="text-align:right;">
7717
</td>
<td style="text-align:right;">
7792
</td>
<td style="text-align:right;">
7836
</td>
</tr>
<tr>
<td style="text-align:left;">
Feb
</td>
<td style="text-align:right;">
8106
</td>
<td style="text-align:right;">
6981
</td>
<td style="text-align:right;">
7306
</td>
<td style="text-align:right;">
7461
</td>
<td style="text-align:right;">
6957
</td>
<td style="text-align:right;">
6892
</td>
</tr>
<tr>
<td style="text-align:left;">
Mar
</td>
<td style="text-align:right;">
8928
</td>
<td style="text-align:right;">
8038
</td>
<td style="text-align:right;">
8124
</td>
<td style="text-align:right;">
7776
</td>
<td style="text-align:right;">
7726
</td>
<td style="text-align:right;">
7791
</td>
</tr>
<tr>
<td style="text-align:left;">
Abr
</td>
<td style="text-align:right;">
9137
</td>
<td style="text-align:right;">
8422
</td>
<td style="text-align:right;">
7870
</td>
<td style="text-align:right;">
7925
</td>
<td style="text-align:right;">
8106
</td>
<td style="text-align:right;">
8129
</td>
</tr>
<tr>
<td style="text-align:left;">
May
</td>
<td style="text-align:right;">
10017
</td>
<td style="text-align:right;">
8714
</td>
<td style="text-align:right;">
9387
</td>
<td style="text-align:right;">
8634
</td>
<td style="text-align:right;">
8890
</td>
<td style="text-align:right;">
9115
</td>
</tr>
<tr>
<td style="text-align:left;">
Jun
</td>
<td style="text-align:right;">
10826
</td>
<td style="text-align:right;">
9512
</td>
<td style="text-align:right;">
9556
</td>
<td style="text-align:right;">
8945
</td>
<td style="text-align:right;">
9299
</td>
<td style="text-align:right;">
9434
</td>
</tr>
</tbody>
</table>
<p>En la figura podemos observar que los datos presentan claramente una componente estacional con periodo <span class="math inline">\(d=12\)</span>.</p>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-28-1.svg" /><!-- --></p>
<p>Será conveniente para el primer método indexar los datos por mes y año. Entonces <span class="math inline">\(X_{j,k}, j=1,\ldots,12, k=1,\ldots,6\)</span> denotará el número de muertes accidentales reportados para el <span class="math inline">\(j\)</span>-ésimo mes del <span class="math inline">\(k\)</span>-ésimo año, <span class="math inline">\((1972+k)\)</span>. En otras palabras, definimos <span class="math display">\[X_{j,k}=X_{j+12(k-1)},\quad j=1,\ldots,12; k=1,\ldots,6.\]</span></p>
<ol style="list-style-type: decimal">
<li><strong>Método E1: Método de la tendencia pequeña</strong>. Si la tendencia es pequeña (como en los datos de accidentes) no es irrazonable suponer que el término de la tendencia es constante, digamos <span class="math inline">\(T_k\)</span> para el año <span class="math inline">\(k\)</span>. Dado que <span class="math inline">\(\sum_{j=1}^{12}E_j=0\)</span>, nos lleva al estimador insesgado natural para la tendencia
<span class="math display" id="eq:eq-estimador-Tj-accidentes">\[\begin{equation}
\hat{T}_k = \frac{1}{12}\sum_{j=1}^{12}X_{j,k},
\tag{2.43}
\end{equation}\]</span>
mientras que para la estacionalidad <span class="math inline">\(E_j, j=1,\ldots,12\)</span> tenemos el estimador
<span class="math display" id="eq:eq-estimador-Et-accidentes">\[\begin{equation}
\hat{E}_j = \frac{1}{6}\sum_{k=1}^6(X_{j,k}-\hat{T}_k),
\tag{2.44}
\end{equation}\]</span>
el cual automáticamente satisface el requisito de que <span class="math inline">\(\sum_{j=1}^{12}\hat{E}_j=0\)</span>. El término de error estimado para el mes <span class="math inline">\(j\)</span> del año <span class="math inline">\(k\)</span> es por supuesto
<span class="math display" id="eq:eq-estimador-epsilon-t-accidentes">\[\begin{equation}
\hat{\epsilon}_{j,k} = X_{j,k}-\hat{T}_k-\hat{E}_j, \quad j=1,\ldots,12; k=1,\ldots,6.
\tag{2.45}
\end{equation}\]</span>
La generalización de <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estimador-Tj-accidentes">(2.43)</a> a <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estimador-epsilon-t-accidentes">(2.45)</a> para datos con estacionalidad con un periodo distinto de 12 es bastante sencillo de realizar, simplemente cambiamos 12 por el correspondiente valor de <span class="math inline">\(d\)</span>. Así, en general, si tenemos <span class="math inline">\(n\)</span> años (meses, semanas, días, etc.) y estacionalidad con periodo <span class="math inline">\(d\)</span>, los estimadores seran:</li>
</ol>
Para la tendencia <span class="math inline">\(T_k\)</span>:
<span class="math display" id="eq:eq-estimador-Tk-E1">\[\begin{equation}
\hat{T}_k=\frac{1}{d}\sum_{j=1}^dX_{j,k}
\tag{2.46}
\end{equation}\]</span>
Para la estacionalidad <span class="math inline">\(E_j\)</span>:
<span class="math display" id="eq:eq-estimador-Ej-E1">\[\begin{equation}
\hat{E}_j=\frac{1}{n}\sum_{k=1}^n(X_{j,k}-\hat{T}_k),\quad j=1,\ldots,d
\tag{2.47}
\end{equation}\]</span>
Para el error
<span class="math display" id="eq:eq-estimador-error-E1">\[\begin{equation}
\hat{\epsilon}_{j,k}=X_{j,k}-\hat{T}_k-\hat{E}_j,\quad k=1,\ldots,n; j=1,\ldots,d.
\tag{2.48}
\end{equation}\]</span>
<p>Las Figuras siguientes muestran respectivamente las observaciones con la tendencia removida <span class="math inline">\(X_{j,k}-\hat{T}_k\)</span>, la componente estacional estimada <span class="math inline">\(\hat{E}_j\)</span> y las observaciones con la tendencia y la estacionalidad removida <span class="math inline">\(\hat{\epsilon}_{j,k}=X_{j,k}-\hat{T}_k-\hat{E}_j\)</span>. En la última gráfica (para el error) no se observa una aparente tendencia o estacionalidad.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimacion de la tendencia</span>
Tk=<span class="kw">numeric</span>(n<span class="op">*</span>d)
<span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
{
  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>d)
  {
    Tk[(k<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>d<span class="op">+</span>j]=Tk[(k<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>d<span class="op">+</span>j]<span class="op">+</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">12</span>)<span class="op">*</span>X[j,k<span class="op">+</span><span class="dv">1</span>]
  }
}
<span class="co"># Grafico con la tendencia removida</span>
<span class="kw">plot</span>(V<span class="op">-</span>Tk,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Meses&quot;</span>,<span class="dt">ylab =</span> <span class="st">&quot;Num. de accidentes&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Accidentes mortales mensuales con la tendencia T_k removida&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-29-1.svg" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimacion de la estacionalidad</span>
Ej=<span class="kw">numeric</span>(n<span class="op">*</span>d)
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>d)
{
  aux=<span class="dv">0</span>
  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
  {
    aux=aux<span class="op">+</span>(X[j,k<span class="op">+</span><span class="dv">1</span>]<span class="op">-</span>Tk[(k<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>d<span class="op">+</span>j])
  }
  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
  {
    Ej[(k<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>d<span class="op">+</span>j]=(<span class="dv">1</span><span class="op">/</span>n)<span class="op">*</span>aux
  }
}
<span class="co"># Grafico de la estacionalidad</span>
<span class="kw">plot</span>(Ej,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Meses&quot;</span>,<span class="dt">ylab =</span> <span class="st">&quot;Num. de accidentes&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Estacionalidad de los accidentes mortales mensuales&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-29-2.svg" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimacion del error</span>
error=V<span class="op">-</span>Tk<span class="op">-</span>Ej
<span class="co"># Grafico del error estimado</span>
<span class="kw">plot</span>(error,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Meses&quot;</span>,<span class="dt">ylab =</span> <span class="st">&quot;Error estimado&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Error estimado de los accidentes mortales&quot;</span>)
<span class="kw">grid</span>(<span class="dt">col =</span> <span class="st">&quot;darkgray&quot;</span>)     </code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-29-3.svg" /><!-- --></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Método E2: Estimación por promedio móvil</strong>. El siguiente método es preferible al Método E1 ya que no se basa en la suposición de que <span class="math inline">\(T_t\)</span> es casi constante sobre cada ciclo de estacionalidad.</li>
</ol>
Suponga que tenemos las observaciones <span class="math inline">\(\{x_1,\ldots,x_n\}\)</span>. El priemr paso es estimar la tendencia aplicando un filtro de promedio móvil especialmente elegido para eliminar la componente estacional y para amortiguar el ruido. Si el periodo <span class="math inline">\(d\)</span> es par, digamos <span class="math inline">\(d=2q\)</span>, entonces usamos
<span class="math display" id="eq:eq-filtro-especial-metodo-E2">\[\begin{equation}
\hat{T}_t = (0.5x_{t-q} + x_{t-q+1} + \cdots + x_{t+q-1} + 0.5x_{t+q})/d, q&lt;t\leq n-q.
\tag{2.49}
\end{equation}\]</span>
Si el periodo es impar, digamos <span class="math inline">\(d=2q+1\)</span>, entonces usamos un promedio móvil simple
<span class="math display" id="eq:eq-filtro-promedio-movil-metodo-E2">\[\begin{equation}
\hat{T}_t=\frac{1}{d}\sum_{j=-q}^qX_{t-j},\quad q+1\leq t\leq n-q
\tag{2.50}
\end{equation}\]</span>
<p>nuevamente, haciendo uso del ejemplo de accidentes mortales, la figura siguiente muestra la tendencia estimada <span class="math inline">\(\hat{T}_t\)</span> usando el filtro mostrado en <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-filtro-especial-metodo-E2">(2.49)</a>. También muestra la tendencia constante a trozos obtenida por el Método E1. En la misma se puede observar que para los ciclos 2 a 5 la tendencia se mantiene cercana, pero para los ciclos 1 y 6 hay una diferencia mas marcada.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Filtro para ciclo par d</span>
q=d<span class="op">/</span><span class="dv">2</span>
N=n<span class="op">*</span>d
aux=<span class="dv">0</span>
T.est=<span class="kw">numeric</span>(N)
<span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N)
{
  <span class="cf">if</span> (t<span class="op">&lt;=</span>q<span class="op">|</span>t<span class="op">&gt;</span>N<span class="op">-</span>q)
  {
    T.est[t]=V[t]
  }
  <span class="cf">else</span>
  {
    aux=<span class="dv">0</span>
    <span class="cf">for</span> (k <span class="cf">in</span> <span class="op">-</span>q<span class="op">:</span>q)
    {
      <span class="cf">if</span> (k<span class="op">==-</span>q<span class="op">|</span>k<span class="op">==</span>q)
      {
        aux=aux<span class="op">+</span><span class="fl">0.5</span><span class="op">*</span>V[t<span class="op">+</span>k]
      }
      <span class="cf">else</span>
      {
        aux=aux<span class="op">+</span>V[t<span class="op">+</span>k]
      }
    }
    T.est[t]=(<span class="dv">1</span><span class="op">/</span>d)<span class="op">*</span>aux
  }
}
<span class="co"># Grafico de las tendencias con los metodos E1 y E2</span>
<span class="kw">plot</span>(T.est,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Meses&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Num. de accidentes&quot;</span>)
<span class="kw">lines</span>(Tk,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-30-1.svg" /><!-- --></p>
El segundo paso, es estimar la componente estacional. Para cada <span class="math inline">\(k=1,\ldots,d\)</span>, calculamos el promedio <span class="math inline">\(w_k\)</span> de las desviaciones <span class="math inline">\(\{(X_{k+jd}-\hat{T}_{k+jd}):q&lt;k+jd\leq n-q\}\)</span>. Dado que este promedio de desviaciones no necesariamente suma cero, estimamos la componente estacional <span class="math inline">\(E_k\)</span> como
<span class="math display" id="eq:eq-estimador-Et-metodo-E2">\[\begin{equation}
\hat{E}_k = w_k -\frac{1}{d}\sum_{i=1}^dw_i,\quad k=1,\ldots,d,
\tag{2.51}
\end{equation}\]</span>
<p>y <span class="math inline">\(\hat{E}_k=\hat{E}_{k-d},k&gt;d\)</span>.</p>
Los datos sin la componente estacional se definen entonces como la serie original con la componente estacional removida, es decir,
<span class="math display" id="eq:eq-serie-destacionalizada-E2">\[\begin{equation}
d_t = X_t-\hat{E}_t,\quad t=1,\ldots,n.
\tag{2.52}
\end{equation}\]</span>
<p>Finalmente, reestimamos la tendencia de <span class="math inline">\(\{d_t\}\)</span> aplicando un filtro de promedio móvil como se describió para los datos no estacionales (método T2) o fijando un polinomio de grado <span class="math inline">\(k\)</span> a la serie <span class="math inline">\(\{d_t\}\)</span>. El término del ruido estimado llega a ser entonces <span class="math display">\[\hat{\epsilon}_t = X_t - \hat{E}_t - \hat{E}_t, \quad t=1,\ldots,n.\]</span> Los resultados de aplicar los Métodos E1 y E2 a los datos de accidentes mortales son casi iguales, dado que en este caso la constante a trozos y el promedio móvil de <span class="math inline">\(\hat{T}_t\)</span> están razonablemente cercanos.</p>
<p>Una comparación de los valores estimados de <span class="math inline">\(\hat{E}_k, k=1,\ldots,12\)</span>, obtenido con ambos métodos se muestra en la tabla siguiente</p>
<table>
<thead>
<tr class="header">
<th>k</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mét E1</td>
<td>-7434</td>
<td>-1504</td>
<td>-724</td>
<td>-523</td>
<td>338</td>
<td>808</td>
<td>1665</td>
<td>961</td>
<td>-87</td>
<td>197</td>
<td>-321</td>
<td>-67</td>
</tr>
<tr class="even">
<td>Mét E2</td>
<td>-804</td>
<td>-1522</td>
<td>-737</td>
<td>-526</td>
<td>343</td>
<td>746</td>
<td>1680</td>
<td>987</td>
<td>-109</td>
<td>258</td>
<td>-259</td>
<td>-57</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Método E3: Diferenciación a paso <span class="math inline">\(\mathbf{d}\)</span></strong>. La técnica de diferenciación la cual aplicamos antes a datos no estacionales se pueden adaptar para lidiar con el caso estacional de periodo <span class="math inline">\(d\)</span> introduciendo el operador de diferencia de paso <span class="math inline">\(d\)</span>, <span class="math inline">\(\nabla_d\)</span> definido por
<span class="math display" id="eq:eq-operador-diferencia-paso-d">\[\begin{equation}
\nabla_dX_t = X_t-X_{t-d} = (1-B^d)X_t.
\tag{2.53}
\end{equation}\]</span>
Este operador no debe confundirse con el operador <span class="math inline">\(\nabla^d = (1-B)^d\)</span> definido por ().</li>
</ul>
<p>Aplicando el operador <span class="math inline">\(\nabla_d\)</span> al modelo <span class="math display">\[X_t = T_t + E_t + \epsilon_t,\]</span> donde <span class="math inline">\(\{E_t\}\)</span> tiene periodo <span class="math inline">\(d\)</span>, obtenemos <span class="math display">\[\nabla_dX_t = T_t-T_{t-d} + \epsilon_t-\epsilon_{t-d},\]</span> lo cual nos da una descomposición de la diferencia <span class="math inline">\(\nabla_dX_t\)</span> en una componente de tendencia <span class="math inline">\((T_t-T_{t-d})\)</span> y un término de ruido <span class="math inline">\((\epsilon_t-\epsilon_{t-d})\)</span>. La tendencia <span class="math inline">\((T_t-T_{t-d})\)</span> se puede eliminar usando los métodos ya descritos, por ejemplo, aplicando alguna potencia del operador <span class="math inline">\(\nabla\)</span>. La figura siguiente muestra el resultado de aplicar el operador <span class="math inline">\(\nabla_{12}\)</span> a los datos de accidentes mortales.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Operador Nabla_d, usamos la funcion diff con lag=12</span>
NdX=<span class="kw">diff</span>(V,<span class="dt">lag=</span><span class="dv">12</span>)
<span class="kw">plot</span>(NdX,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-31-1.svg" /><!-- --></p>
<p>La componente estacional evidente en la Figura~ está ausente en la Figura de <span class="math inline">\(\nabla_{12}X_t,13\leq t\leq72\)</span>. Sin embargo todavía parece haber una tendencia decreciente. Si ahora aplicamos el operador <span class="math inline">\(\nabla\)</span> a <span class="math inline">\(\nabla_{12}X_t\)</span> y graficamos las diferencias <span class="math inline">\(\nabla\nabla_{12}X_t,t=14,\ldots,72\)</span> obtenemos el gráfico mostrado en la Figura siguiente, la cual no tiene una aparente tendencia o componente estacional.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">DNdX=<span class="kw">diff</span>(NdX)
<span class="kw">plot</span>(DNdX,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-32-1.svg" /><!-- --></p>
</div>
</div>
<div id="estimacion-de-la-tendencia-por-regresion-clasica" class="section level2">
<h2><span class="header-section-number">2.3</span> Estimación de la tendencia por regresión clásica</h2>
<p>Los modelos de regresión son importantes para modelos en el dominio de tiempo y de frecuencia que discutiremos posteriormente. La idea principal depende de poder expresar una serie respuesta <span class="math inline">\(X_t\)</span> como una combinación lineal de entradas <span class="math inline">\(z_{t_1},z_{t_2},\ldots,z_{t_q}\)</span>. La estimación de los coeficientes <span class="math inline">\(\beta_1,\beta_2,\ldots,\beta_q\)</span> de la combinación por mínimos cuadrados proporciona un método para modelar <span class="math inline">\(X_t\)</span> en términos de las entradas.</p>
<div id="regresion-clasica" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Regresión Clásica</h3>
Supongamos que tenemos <span class="math inline">\(X_t\)</span>, para <span class="math inline">\(t=1,2,\ldots,n\)</span> influenciada por una colección de series independientes <span class="math inline">\(z_{t_1},z_{t_2},\ldots,z_{t_q}\)</span>, donde consideraremos primero que las entradas son fijas y conocidas. Podemos expresar esta relación como
<span class="math display" id="eq:eq-regresion-lineal">\[\begin{equation}
X_t=\beta_1z_{t_1}+\beta_2z_{t_2}+\cdots+\beta_qz_{t_q}+w_t
\tag{2.54}
\end{equation}\]</span>
<p>donde <span class="math inline">\(\beta_1,\beta_2,\ldots,\beta_q\)</span> son los coeficientes de regresión fijos y desconocidos, <span class="math inline">\(\{w_t\}\)</span> es un error aleatorio o un proceso de ruido consistente de variables normales iid con media cero y varianza <span class="math inline">\(\sigma_w^2\)</span>.</p>
<p>El modelo lineal descrito en <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-regresion-lineal">(2.54)</a> se puede escribir de forma más general por medio de definir los vectores columna <span class="math inline">\(\mathbf{z}_t=(z_{t_1},z_{t_2},\ldots,z_{t_q})^t\)</span> y <span class="math inline">\(\mathbf{\beta}=(\beta_1,\beta_2,\ldots,\beta_q)^t\)</span> donde <span class="math inline">\(t\)</span> denota la traspuesta, así <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-regresion-lineal">(2.54)</a> será</p>
<span class="math display" id="eq:eq-regresion-lineal-2">\[\begin{equation}
X_t=\mathbf{\beta}^t\mathbf{z}_t+w_t
\tag{2.55}
\end{equation}\]</span>
<p>donde <span class="math inline">\(w_t\sim iid(0,\sigma_w^2)\)</span>. Es natural considerar la estimación de los coeficientes del vector <span class="math inline">\(\mathbf{\beta}\)</span> minimizando la suma residual de cuadrados</p>
<span class="math display" id="eq:eq-suma-residual-cuadrados">\[\begin{equation}
RSS=\sum_{t=1}^{n}(X_t-\mathbf{\beta}^t\mathbf{z}_t)^2
\tag{2.56}
\end{equation}\]</span>
<p>con respecto a <span class="math inline">\(\beta_1,\beta_2,\ldots,\beta_q\)</span>. Minimizando RSS obtenemos el estimador común de mínimos cuadrados. Esta minimización se puede hacer por diferenciación de <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-suma-residual-cuadrados">(2.56)</a> con respecto al vector <span class="math inline">\(\mathbf{\beta}\)</span> o usando las propiedades de proyección. En la notación anterior, obtenemos la ecuación normal</p>
<span class="math display" id="eq:eq-regresion-lineal-normal">\[\begin{equation}
\left(\sum_{t=1}^{n}\mathbf{z}_t\mathbf{z}_t^t\right)\hat{\mathbf{\beta}}=\sum_{t=1}^{n}\mathbf{z}_tX_t
\tag{2.57}
\end{equation}\]</span>
<p>Definiendo la matriz <span class="math inline">\(Z=(\mathbf{z}_1,\mathbf{z}_2,\ldots,\mathbf{z}_n)^t\)</span> como una matriz <span class="math inline">\(n\times q\)</span> compuesta de <span class="math inline">\(n\)</span> muestras de las variables de entradas y el vector observado <span class="math inline">\(\mathbf{x}=(x_1,x_2,\ldots,x_n)^t\)</span> se puede hacer una simplificación de la notación. Esta identificación nos lleva a</p>
<span class="math display" id="eq:eq-regresion-matriz">\[\begin{equation}
(Z^tZ)\hat{\mathbf{\beta}}=Z^t\mathbf{x}
\tag{2.58}
\end{equation}\]</span>
<p>y la solución es</p>
<span class="math display" id="eq:eq-solucion-regresion-matriz">\[\begin{equation}
\hat{\mathbf{\beta}}=(Z^tZ)^{-1}Z^t\mathbf{x},
\tag{2.59}
\end{equation}\]</span>
<p>cuando la matriz <span class="math inline">\(Z^tZ\)</span> es de rango <span class="math inline">\(q\)</span>. El residual minimizado de suma de cuadrados <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-suma-residual-cuadrados">(2.56)</a> tiene la forma matricial equivalente</p>
<span class="math display" id="eq:eq-suma-residual-cuadrados-matricial">\[\begin{eqnarray}
RSS&amp;=&amp;(\mathbf{x}-Z\hat{\mathbf{\beta}})^t(\mathbf{x}-Z\hat{\mathbf{\beta}})\\ \nonumber
&amp;=&amp;\mathbf{x}^t\mathbf{x}-\hat{\mathbf{\beta}}^tZ^t\mathbf{x}\\ \nonumber
&amp;=&amp;\mathbf{x}^t\mathbf{x}-\mathbf{x}^tZ(Z^tZ)^{-1}Z^t\mathbf{x}.
\tag{2.60}
\end{eqnarray}\]</span>
<p>El estimador común de mínimos cuadrados es insesgado, esto es, <span class="math inline">\(\mathbb{E}(\hat{\mathbf{\beta}})=\mathbf{\beta}\)</span>, y tiene la menor varianza de todos los estimadores insesgados lineales.</p>
<p>Si los errores <span class="math inline">\(w_t\)</span> son normalmente distribuidos (Gaussianos), <span class="math inline">\(\hat{\mathbf{\beta}}\)</span> es también el estimador de máxima verosimilitud para <span class="math inline">\(\mathbf{\beta}\)</span> y es normalmente distribuido con</p>
<span class="math display" id="eq:eq-covarianza-beta-estimado">\[\begin{eqnarray}
\text{cov}(\hat{\mathbf{\beta}})&amp;=&amp;\sigma_w^2\left(\sum_{t=1}^{n}\mathbf{z}_t\mathbf{z}_t^t\right)^{-1}\\ \nonumber
&amp;=&amp;\sigma_w^2(Z^tZ)^{-1}\\ \nonumber
&amp;=&amp;\sigma_w^2C,
\tag{2.61}
\end{eqnarray}\]</span>
<p>donde</p>
<span class="math display" id="eq:eq-matriz-C">\[\begin{equation}
C=(Z^tZ)^{-1}.
\tag{2.62}
\end{equation}\]</span>
Un estimador insesgado para la varianza <span class="math inline">\(\sigma_w^2\)</span> es
<span class="math display" id="eq:eq-estimador-insesgado-varianza">\[\begin{equation}
s_w^2=\frac{RSS}{n-q}
\tag{2.63}
\end{equation}\]</span>
<p>contrastado con el estimador de máxima verosimilitud <span class="math inline">\(\hat{\sigma}_w^2=RSS/n\)</span> el cual tiene divisor <span class="math inline">\(n\)</span>. Bajo la suposición de que <span class="math inline">\(s_w^2\)</span> tiene distribución proporcional a una variable aleatoria chi-cuadrado con <span class="math inline">\(n-q\)</span> grados de libertad, <span class="math inline">\(\chi_{n-q}^2\)</span>, e independiente de <span class="math inline">\(\hat{\beta}\)</span>, se sigue que</p>
<span class="math display" id="eq:eq-estadistico-t">\[\begin{equation}
t_{n-q}=\frac{(\hat{\beta}_i-\beta_i)}{s_w\sqrt{c_{ii}}}
\tag{2.64}
\end{equation}\]</span>
<p>tiene distribución <span class="math inline">\(t\)</span>-de Student con <span class="math inline">\(n-q\)</span> grados de libertad; <span class="math inline">\(c_{ii}\)</span> denota el <span class="math inline">\(i\)</span>-ésimo elemento de la diagonal de <span class="math inline">\(C\)</span>, como se definió en <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-matriz-C">(2.62)</a>.</p>
<p>Hay varios modelos que podemos utilizar de manera de seleccionar el mejor subconjunto de variables independientes. Suponga que tenemos un modelo que sólo considera un subconjunto <span class="math inline">\(q_1&lt;q\)</span> de variables independientes <span class="math inline">\(\mathbf{z}_{1t}=(z_{t_1},z_{t_2},\ldots,z_{t_q1})^t\)</span> que influencian a la variable <span class="math inline">\(X_t\)</span>, así el modelo</p>
<span class="math display" id="eq:eq-modelo-regresion-reducido">\[\begin{equation}
X_t=\mathbf{\beta}_1^t\mathbf{z}_{1t}+w_t
\tag{2.65}
\end{equation}\]</span>
<p>llega a ser la hipótesis nula, donde <span class="math inline">\(\mathbf{\beta}_1=(\beta_1,\beta_2,\ldots,\beta_{q1})^t\)</span> es un subconjunto de los coeficientes de las <span class="math inline">\(q\)</span> variables originales. Podemos contrastar el modelo reducido <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-regresion-reducido">(2.65)</a> contra el modelo completo <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-regresion-lineal-2">(2.55)</a> comparando el residual de la suma de cuadrados bajo los dos modelos usando el estadístico <span class="math inline">\(F\)</span></p>
<span class="math display" id="eq:eq-estadistico-F-residuales">\[\begin{equation}
F_{q-q1,n-q}=\frac{RSS_1-RSS}{RSS}\frac{n-q}{q-q1}
\tag{2.66}
\end{equation}\]</span>
<p>el cual tiene distribución <span class="math inline">\(F\)</span> con <span class="math inline">\(q-q1\)</span> y <span class="math inline">\(n-q\)</span> grados de libertad cuando <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estadistico-F-residuales">(2.66)</a> es el modelo correcto. La información envuelta en la prueba se resume en una tabla de Análisis de Varianza (ANOVA) como la mostrada en la Tabla siguiente para este caso particular. La diferencia en el numerador es llamada regresión de la suma de cuadrados.</p>
<table style="width:74%;">
<colgroup>
<col width="11%" />
<col width="8%" />
<col width="27%" />
<col width="26%" />
</colgroup>
<thead>
<tr class="header">
<th>Fuente</th>
<th>g.l</th>
<th>Suma de cuadrados</th>
<th>Medias Cuadrados</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(z_{t,q_1+1},\ldots,z_{t,q}\)</span></td>
<td><span class="math inline">\(q-q_1\)</span></td>
<td><span class="math inline">\(SS_{reg}=RSS_1-RSS\)</span></td>
<td><span class="math inline">\(MS_{reg}=SS_{reg}/(q-q_1)\)</span></td>
</tr>
<tr class="even">
<td>Error</td>
<td><span class="math inline">\(n-q\)</span></td>
<td><span class="math inline">\(RSS\)</span></td>
<td><span class="math inline">\(s_e^2=RSS/(n-q)\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(n-q_1\)</span></td>
<td><span class="math inline">\(RSS_1\)</span></td>
<td></td>
</tr>
</tbody>
</table>
En términos de la Tabla, por convención escribimos el estadístico <span class="math inline">\(F\)</span> dado en <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estadistico-F-residuales">(2.66)</a> como el radio de dos medias cuadrados, obteniéndose
<span class="math display" id="eq:eq-estadistico-F-radio-medias">\[\begin{equation}
F_{q-q1,n-q}=\frac{M S_{reg}}{s_w^2}.
\tag{2.67}
\end{equation}\]</span>
Un caso de especial interés es para <span class="math inline">\(q_1=1\)</span> y <span class="math inline">\(z_{1t}=1\)</span>, así el modelo en <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-regresion-reducido">(2.65)</a> es <span class="math display">\[X_t=\beta_1+w_t\]</span> y la proporción de variación explicada por las otras variables es
<span class="math display" id="eq:eq-proporcion-variacion-explicada">\[\begin{equation}
R_{xz}^2=\frac{RSS_0-RSS}{RSS_0},
\tag{2.68}
\end{equation}\]</span>
donde la suma residual de cuadrados bajo el modelo reducido dada por
<span class="math display" id="eq:eq-suma-residual-reducido">\[\begin{equation}
RSS_0=\sum_{t=1}^{n}(X_t-\bar{X})^2
\tag{2.69}
\end{equation}\]</span>
<p>es precisamente la suma de desviaciones al cuadrado de la media <span class="math inline">\(\bar{X}\)</span>. La medida <span class="math inline">\(R_{xz}^2\)</span> es la correlación múltiple cuadrado entre <span class="math inline">\(X_t\)</span> y <span class="math inline">\(z_{t2},z_{t3},\ldots,z_{tq}\)</span>.</p>
<p>Las técnicas discutidas se pueden usar para hacer comparación entre varios modelos. Estas pruebas han sido usadas en el pasado en una manera gradual, donde las variables son añadidas o suprimidas cuando los valores de la prueba <span class="math inline">\(F\)</span> exceden o fallan en exceder algunos niveles predeterminados. El procedimiento, llamado regresión múltiple por pasos, es útil para conseguir un conjunto de variables que sea de utilidad. Una manera alternativa es enfocándose en un procedimiento para selección del modelo que no sea secuencial, sino simplemente evaluar cada modelo en base a sus propios méritos.</p>
Suponga que consideramos un modelo de regresión con <span class="math inline">\(k\)</span> coeficientes y denotemos el estimador de máxima verosimilitud para la varianza como
<span class="math display" id="eq:eq-estimador-emv-varianza">\[\begin{equation}
\hat{\sigma}_k^2=\frac{RSS_k}{n}
\tag{2.70}
\end{equation}\]</span>
<p>donde <span class="math inline">\(RSS_k\)</span> denota la suma residual de cuadrados bajo el modelo con <span class="math inline">\(k\)</span> coeficientes de regresión. Entonces, Akaike (1969, 1973, 1974) sugirió medir la bondad del ajuste para este modelo en particular equilibrando el error del ajuste contra el número de parámetros en el modelo; definiendo lo siguiente</p>

<div class="definition">
<span id="def:defi-AIC" class="definition"><strong>Definición 2.16  (Criterio de Información de Akaike (AIC))  </strong></span>El Criterio de Información de Akaike se define como
<span class="math display" id="eq:eq-AIC">\[\begin{equation}
AIC=\ln\hat{\sigma}_k^2+\frac{n+2k}{n}
\tag{2.71}
\end{equation}\]</span>
<p>donde <span class="math inline">\(\hat{\sigma}_k^2\)</span> está dado por <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-estimador-emv-varianza">(2.70)</a> y <span class="math inline">\(k\)</span> es el número de parámetros en el modelo</p>
</div>

<hr />
<p>El <em>criterio de información de Akaike</em> (AIC) es una medida de la calidad relativa de un modelo estadístico, para un conjunto dado de datos. Como tal, el AIC proporciona un medio para la selección del modelo. El valor de <span class="math inline">\(k\)</span> que minimiza <span class="math inline">\(AIC\)</span> especifica el mejor modelo. La idea es que la minimización de <span class="math inline">\(\hat{\sigma}_k^2\)</span> sea razonablemente objetiva, excepto que decrezca monótonamente cuando <span class="math inline">\(k\)</span> crece. Por lo tanto, debemos penalizar la variación del error por un término proporcional al número de parámetros. La elección del término de penalización dado por <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-AIC">(2.71)</a> no es único.</p>

<div class="example">
<span id="exm:ejem-temperatura-global" class="example"><strong>Ejemplo 2.6  (Temperatura global)  </strong></span>Consideremos los datos de temperatura global del archivo “globtemp2.txt”. Estos datos corresponden a 125 años de mediciones de temperatura, representan la desviación promedio entre las temperaturas en tierra y aire medidos en grados centígrados (°C), desde 1880 hasta 2004.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Lectura del archivo de datos</span>
globtemp=<span class="kw">read.table</span>(<span class="st">&quot;data/globtemp2.txt&quot;</span>)
<span class="co"># Grafico de la serie de datos</span>
<span class="kw">plot</span>(globtemp[,<span class="dv">1</span>],globtemp[,<span class="dv">2</span>],<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Años&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Desv. temp. global (°c)&quot;</span>,
     <span class="dt">main=</span><span class="st">&quot;Desviación de la temperatura promedio global (1880-2004)&quot;</span>)
<span class="kw">grid</span>(<span class="dt">col =</span> <span class="st">&quot;darkgray&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-33-1.svg" /><!-- --></p>
<p>Ajustemos una regresión simple de la forma <span class="math display">\[x_t+\beta_1+\beta_2t+w_t\text{, con }t=1900,1901,\ldots,1997.\]</span> Esta es la forma del modelo de regresión <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-regresion-lineal">(2.54)</a> con <span class="math inline">\(q=2,z_{t_1}=1,z_{t_2}=t\)</span>.</p>
<p>Note que podemos usar <span class="math inline">\(t=0,1,\ldots,97\)</span>, sin afectar la interpretación del coeficiente de la pendiente <span class="math inline">\(\beta_2\)</span>, solo se afectaría la intercepción <span class="math inline">\(\beta_1\)</span>.</p>
<p>Usando regresión lineal obtuvimos los valores estimados de los coeficientes: <span class="math inline">\(\hat{\beta}_1=-10.44,\hat{\beta}_2=0.0053\)</span>, con un error estándar de <span class="math inline">\(4.9\times10^{-4}\)</span>, dando un incremento estimado de 0.6 grados por cada 100 años. En la figura podemos observar la serie de tiempo con la recta de regresión</p>
<p><span class="math display">\[\hat{x}_t=-10.44+0.0053t\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Convertimos a serie de tiempo</span>
gtemp=<span class="kw">ts</span>(globtemp[,<span class="dv">2</span>],<span class="dt">start =</span> <span class="dv">1880</span>)
<span class="co"># Tomamos el subconjunto de 1900 a 1997</span>
gtemp=<span class="kw">window</span>(gtemp,<span class="dt">start =</span> <span class="dv">1900</span>, <span class="dt">end =</span> <span class="dv">1997</span>)
<span class="co"># Calculamos la regresion lineal</span>
fit=<span class="kw">lm</span>(gtemp<span class="op">~</span><span class="kw">time</span>(gtemp),<span class="dt">na.action =</span> <span class="ot">NULL</span>)
<span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gtemp ~ time(gtemp), na.action = NULL)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.3578 -0.0899 -0.0055  0.1064  0.2671 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.04e+01   9.56e-01   -10.9   &lt;2e-16 ***
## time(gtemp)  5.36e-03   4.91e-04    10.9   &lt;2e-16 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.137 on 96 degrees of freedom
## Multiple R-squared:  0.554,  Adjusted R-squared:  0.549 
## F-statistic:  119 on 1 and 96 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Grafico de la serie y la regresion</span>
<span class="kw">plot</span>(gtemp,<span class="dt">type =</span> <span class="st">&quot;o&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Años&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Temperatura (°C)&quot;</span>, 
    <span class="dt">col =</span>  <span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(fit, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)
<span class="kw">grid</span>(<span class="dt">col=</span><span class="st">&quot;darkgray&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-34-1.svg" /><!-- --></p>
<p>Podemos ver los residuales de la temperatura global <span class="math inline">\(e_t=x_t-\hat{x}_t\)</span>, así como la ACF de los mismos. En las gráficas siguientes se muestran los mismo. En el gráfico para la ACF podemos observar que existe una correlación importante entre <span class="math inline">\(x_t\)</span> y <span class="math inline">\(x_{t-1}\)</span>, y también cierta correlación entre <span class="math inline">\(x_t\)</span> y <span class="math inline">\(x_{t-4},x_{t-5}\)</span> y <span class="math inline">\(x_{t-6}\)</span>. En el capítulo de modelos <span class="math inline">\(AR\)</span> veremos más sobre esta relación.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Residuales</span>
e.temp=gtemp<span class="op">-</span>fit<span class="op">$</span>fitted.values
<span class="kw">plot</span>(e.temp, <span class="dt">xlab=</span><span class="st">&quot;Años&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Residuales de la temperatura global&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-35-1.svg" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ACF de los residuales</span>
<span class="kw">acf</span>(e.temp, <span class="dt">main=</span><span class="st">&quot;ACF de los residuales de la temperatura global&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/unnamed-chunk-35-2.svg" /><!-- --></p>
<hr />

<div class="example">
<p><span id="exm:ejem-regresion-senal-ruido" class="example"><strong>Ejemplo 2.7  (Uso de regresión para descubrir una señal de ruido)  </strong></span> Consideremos el modelo</p>
<span class="math display" id="eq:eq-modelo-senosoidal">\[\begin{equation}
x_t=A\cos(2\pi\omega t+\phi)+w_t
\tag{2.72}
\end{equation}\]</span>
<p>donde <span class="math inline">\(\omega=1/50,A=2,\phi=0.6\pi\)</span> y <span class="math inline">\(\sigma_w=5\)</span>, para <span class="math inline">\(t=1,2,\ldtos,500\)</span>.</p>
Usando identidad trigonométrica, podemos escribir
<span class="math display">\[\begin{eqnarray*}
A\cos(2\pi\omega t+\phi)&amp;=&amp;A\cos(\phi)\cos(2\pi\omega t)-A\sin(\phi)\sin(2\pi\omega t)\\
        &amp;=&amp;\beta_1\cos(2\pi\omega t)+\beta_2\sin(2\pi\omega t),
\end{eqnarray*}\]</span>
<p>donde <span class="math inline">\(\beta_1=A\cos(\phi)\)</span> y <span class="math inline">\(\beta_2=-A\sin(\phi)\)</span>. Ahora podemos escribir el modelo <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-senosoidal">(2.72)</a> en la forma de regresión lineal dada por</p>
<span class="math display" id="eq:eq-modelo-senosoidal-lineal">\[\begin{equation}
x_t=\beta_1\cos(2\pi t/50)+\beta_2\sin(2\pi t/50)+w_t.
\tag{2.73}
\end{equation}\]</span>
<p>Usando regresión lineal sobre la serie generada, el modelo fijado será</p>
<span class="math display" id="eq:eq-modelo-regresion-datos">\[\begin{equation}
\hat{x}_t=-0.84_{(0.32})\cos(2\pi t/50)-1.99_{(0.32})\sin(2\pi t/50)
\tag{2.74}
\end{equation}\]</span>
<p>con <span class="math inline">\(\hat{\sigma}_w=5.08\)</span>, donde los valores entre paréntesis son los errores estándar.</p>
Las instrucciones en R son las siguientes:
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">C=<span class="dv">2</span><span class="op">*</span><span class="kw">cos</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span><span class="dv">1</span><span class="op">:</span><span class="dv">500</span><span class="op">/</span><span class="dv">50</span><span class="op">+</span><span class="fl">0.6</span><span class="op">*</span>pi)
w=<span class="kw">rnorm</span>(<span class="dv">500</span>,<span class="dv">0</span>,<span class="dv">1</span>)
Xt=<span class="op">-</span><span class="fl">0.84</span><span class="op">*</span><span class="kw">cos</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span><span class="dv">1</span><span class="op">:</span><span class="dv">500</span><span class="op">/</span><span class="dv">50</span>)<span class="op">-</span><span class="fl">1.99</span><span class="op">*</span><span class="kw">sin</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span><span class="dv">1</span><span class="op">:</span><span class="dv">500</span><span class="op">/</span><span class="dv">50</span>)
<span class="kw">plot</span>(C<span class="op">+</span><span class="dv">5</span><span class="op">*</span>w, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">lines</span>(Xt,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:fig-tema3-regresion-senal-ruido"></span>
<img src="Serie-de-Tiempo-en-R_files/figure-html/fig-tema3-regresion-senal-ruido-1.svg" alt="Datos generados por el modelo senosoidal [línea punteado roja] con modelo de regresión [línea solida azul"  />
<p class="caption">
Figura 2.1: Datos generados por el modelo senosoidal [línea punteado roja] con modelo de regresión [línea solida azul
</p>
</div>
<hr />

<div class="example">
<p><span id="exm:ejem-periodograma-senal-ruido" class="example"><strong>Ejemplo 2.8  (Uso de periodograma para descubrir una señal de ruido)  </strong></span>En algunos ejemplos puede lucir engañoso la periodicidad porque damos por supuesto que conocemos el valor del parámetro <span class="math inline">\(\omega\)</span>. Si no conocemos el parámetro <span class="math inline">\(\omega\)</span>, podemos tratar de fijar el modelo <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-senosoidal">(2.72)</a> usando regresión no lineal con <span class="math inline">\(\omega\)</span> como un parámetro. Otro método es intentar con distintos valores de <span class="math inline">\(\omega\)</span> de forma sistemática.</p>
<p>Una medida apropiada de la presencia de una frecuencia de oscilación de <span class="math inline">\(j\)</span> ciclos en <span class="math inline">\(n\)</span> puntos de tiempos de un conjunto datos podría ser</p>
<span class="math display" id="eq:eq-periodograma">\[\begin{equation}
P(j/n)=\hat{\beta}_1^2(j/n)+\hat{\beta}_2^2(j/n)
\tag{2.75}
\end{equation}\]</span>
<p>lo cual es básicamente una medida de correlación cuadrada. La cantidad <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-periodograma">(2.75)</a> es usualmente llamada el <em>periodograma</em>.</p>
La Figura siguiente muestra el periodograma para los datos generados por <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-modelo-senosoidal">(2.72)</a>, y es fácil descubrir la componente periódica con frecuencia <span class="math inline">\(\omega=0.02=10/500\)</span>.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t=<span class="dv">1</span><span class="op">:</span><span class="dv">500</span>
x=<span class="dv">2</span><span class="op">*</span><span class="kw">cos</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span>t<span class="op">/</span><span class="dv">50</span><span class="op">+</span><span class="fl">0.6</span><span class="op">*</span>pi<span class="op">+</span><span class="kw">rnorm</span>(<span class="dv">500</span>,<span class="dv">0</span>,<span class="dv">5</span>))
I=<span class="kw">abs</span>(<span class="kw">fft</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">500</span>))<span class="op">^</span><span class="dv">2</span>
P=(<span class="dv">4</span><span class="op">/</span><span class="dv">500</span>)<span class="op">*</span>I
f=<span class="dv">0</span><span class="op">:</span><span class="dv">250</span><span class="op">/</span><span class="dv">500</span>
<span class="kw">plot</span>(f, P[<span class="dv">1</span><span class="op">:</span><span class="dv">251</span>],<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;frequency&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot; &quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">seq</span>(<span class="dv">0</span>,.<span class="dv">5</span>,.<span class="dv">02</span>),<span class="dt">lty=</span><span class="st">&quot;dotted&quot;</span>)</code></pre></div>
<p><img src="Serie-de-Tiempo-en-R_files/figure-html/fig-tema3-periodograma-modelo-senosoidal-1.svg" /><!-- --></p>
<hr />
<p>Finalmente mencionamos que no es necesario realizar una regresión grande</p>
<span class="math display" id="eq:eq-regresion-n-medio">\[\begin{equation}
x_t=\sum_{j=0}^{n/2}\beta_1(j/n)\cos(2\pi tj/n)+\beta_2(j/n)\sin(2\pi tj/n)
\tag{2.76}
\end{equation}\]</span>
<p>para obtener los valores de <span class="math inline">\(\beta_1(j/n)\)</span> y <span class="math inline">\(\beta_2(j/n)\)</span> <span class="math inline">\([\beta_2(0)=\beta_2(1/2)=0]\)</span> porque ellos se pueden calcular fácilmente si <span class="math inline">\(n\)</span> es un entero grande. No hay error en <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-regresion-n-medio">(2.76)</a> porque son <span class="math inline">\(n\)</span> observaciones y <span class="math inline">\(n\)</span> parámetros; la regresión ajusta bien. La Transformada Discreta de Fourier (DFT) es un promedio a valores complejos de los datos dados por</p>
<span class="math display" id="eq:eq-DF">\[\begin{equation}
d(j/n)=n^{-1/2}\sum_{t=1}^{n}x_t\exp(-2\pi i tj/n)
\tag{2.77}
\end{equation}\]</span>
<p>a los valores <span class="math inline">\(j/n\)</span> son llamados <em>frecuencias fundamentales</em> o <em>de Fourier</em>.</p>
<p>Como un número grande de cálculos redundantes en <a href="#eq:eq-DFT">(<strong>??</strong>)</a> se pueden realizar rápidamente usando la Transformada Rápida de Fourier (FFT), la cual está disponible en muchos paquete de computación entre ellos Matlab y R. Note que<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<span class="math display" id="eq:eq-periodograma-2">\[\begin{equation}
|d(j/n)|^2=\frac{1}{n}\left(\sum_{t=1}^{n}x_t\cos(2\pi tj/n)\right)^2+\frac{1}{n}\left(\sum_{t=1}^{n}x_t\sin(2\pi tj/n)\right)^2
\tag{2.78}
\end{equation}\]</span>
<p>y esta cantidad es lo que llamamos el periodograma; por lo que podemos escribir</p>
<p><span class="math display">\[I(j/n)=|d(j/n)|^2\]</span></p>
<p>De modo, que podemos calcular el periodograma <a href="caracteristicas-de-series-de-tiempo.html#eq:eq-periodograma">(2.75)</a> usando la expresión</p>
<span class="math display">\[\begin{equation}
P(j/n)=\frac{4}{n}I(j/n)
\end{equation}\]</span>
<<<<<<< HEAD
<p>Discutiremos esta aproximación con más detalles en el Tema [Análisis Espectral].</p>
=======
<p>Discutiremos esta aproximación con más detalles en el Tema <a href="analisis-espectral.html#analisis-espectral">Análisis Espectral</a>.</p>
>>>>>>> d29c4667e48a2762d89d8c516304a5bee625c8e4

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Note que la desigualdad de Cauchy-Schwartz implica <span class="math inline">\(|\gamma(s,t)|^2\leq\gamma(s,s)\gamma(t,t)\)</span>.}.<a href="caracteristicas-de-series-de-tiempo.html#fnref1">↩</a></p></li>
<li id="fn2"><p>Esto depende del hecho de que muchas funciones pueden ser aproximadas bastante bien, en un intervalo de longitud finita, por un polinomio de grado razonablemente bajo.<a href="caracteristicas-de-series-de-tiempo.html#fnref2">↩</a></p></li>
<li id="fn3"><p><span class="math inline">\(e^{-i\alpha}=\cos(\alpha)-i\sin(\alpha)\)</span> y si <span class="math inline">\(z=a-ib\)</span> entonces <span class="math inline">\(|z|^2=z\bar{z}=(a-ib)(a+ib)=a^2+b^2\)</span>.<a href="caracteristicas-de-series-de-tiempo.html#fnref3">↩</a></p></li>
</ol>
</div>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-78759535-1', 'auto');
ga('send', 'pageview');  
</script>
            </section>

          </div>
        </div>
      </div>
<a href="introduccion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelos-de-series-de-tiempo.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/synergyvision/Teoria-de-Portafolio/edit/master/bookdown/200-caracterisitcas-series-tiempo.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Serie-de-Tiempo-en-R.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
<<<<<<< HEAD
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
=======
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
>>>>>>> d29c4667e48a2762d89d8c516304a5bee625c8e4
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
